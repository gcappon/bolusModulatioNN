{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\PY36\\lib\\site-packages\\sklearn\\cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#Loading useful packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import os.path\n",
    "import sys\n",
    "import argparse\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "#General purpose AI packages\n",
    "from sklearn.cross_validation import train_test_split,KFold\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.metrics import confusion_matrix, mean_squared_error\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from sklearn.gaussian_process import GaussianProcess\n",
    "\n",
    "#Keras packages\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout, ActivityRegularization\n",
    "from keras.callbacks import Callback, ModelCheckpoint, EarlyStopping\n",
    "from keras.optimizers import RMSprop\n",
    "from keras import regularizers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "############## LOSSHISTORY CALLBACK CLASS ######################################\n",
    "class LossHistory(Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.losses = []\n",
    "        self.val_losses = []\n",
    "\n",
    "    def on_epoch_end(self, batch, logs={}):\n",
    "        self.losses.append(logs.get('loss'))\n",
    "        self.val_losses.append(logs.get('val_loss'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DATAFILE = os.path.join('data','data.csv')\n",
    "TARGETFILE = os.path.join('data','target.csv')\n",
    "OUTDIR = os.path.join('results')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_nn(X_tr,Y_tr,X_val,Y_val):\n",
    "    \n",
    "    verbose = 1\n",
    "    \n",
    "    #Model callbacks\n",
    "    filepath = os.path.join('results','weights.best.hdf5')\n",
    "    mdlcheck = ModelCheckpoint(filepath, verbose=0, save_best_only=True)\n",
    "    mdllosses = LossHistory()\n",
    "    mdlstop = EarlyStopping(monitor='val_loss', min_delta=0, patience=10, verbose=0, mode='auto')\n",
    "\n",
    "    #Model fit\n",
    "    n_epochs = 5000\n",
    "    n_batch = 68\n",
    "    kf = KFold(n = np.shape(X_tr_val)[0], n_folds = 5)\n",
    "    performance_cv = []\n",
    "    #mdllosses_cv = []\n",
    "    models = []\n",
    "    \n",
    "    i = 1\n",
    "    for tr_idx, val_idx in kf:\n",
    "        #'activation_1': 0, 'activation_2': 1, 'activation_3': 1, 'dropout_1': 0.08813572098580352, \n",
    "        #'dropout_2': 0.03155693545556867, 'fit_n_batch': 68.0, 'n_nodes_1': 436.0, 'n_nodes_2': 969.0, 'n_nodes_3': 373.0\n",
    "        #Build NN\n",
    "        model = Sequential()\n",
    "        model.add(Dense(units=436, input_dim=np.shape(X_tr)[1], activity_regularizer=regularizers.l2(0)))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(Dropout(0.0881357))\n",
    "        model.add(Dense(units=969,activity_regularizer=regularizers.l2(0)))\n",
    "        model.add(Activation('sigmoid'))\n",
    "        model.add(Dropout(0.0315569))\n",
    "        model.add(Dense(units=373,activity_regularizer=regularizers.l2(0)))\n",
    "        model.add(Activation('sigmoid'))\n",
    "        model.add(Dense(units=1))\n",
    "\n",
    "        opt = RMSprop(lr=0.001, rho=0.9, epsilon=1e-08, decay=0.0)\n",
    "        model.compile(loss='mse',optimizer=opt)\n",
    "    \n",
    "        print(\"Fold: \",i,\" of 5\")\n",
    "        i = i+1\n",
    "        X_train, X_valid = X_tr_val[tr_idx], X_tr_val[val_idx]\n",
    "        Y_train, Y_valid = Y_tr_val[tr_idx], Y_tr_val[val_idx]\n",
    "        scaler = StandardScaler().fit(X_train)\n",
    "        X_train = scaler.transform(X_train)\n",
    "        X_valid = scaler.transform(X_valid)\n",
    "\n",
    "        history = model.fit(X_train, Y_train, validation_data = (X_valid, Y_valid),  epochs = n_epochs, batch_size = n_batch, callbacks = [mdlstop,mdlcheck,mdllosses],verbose = verbose)\n",
    "        \n",
    "        #Recalling best weights and appending loss value and loss history\n",
    "        model.load_weights(filepath)\n",
    "        models.append(model)\n",
    "        performance_cv.append(min(mdllosses.val_losses))\n",
    "        #mdllosses_cv.append(mdllosses)\n",
    "        \n",
    "    #Calculating in-cv std \n",
    "    loss_std = np.std(performance_cv)\n",
    "    \n",
    "    print('Obtained loss: ', np.mean(performance_cv), ' (', loss_std, ')')\n",
    "    \n",
    "    return model, min(mdllosses.val_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold:  1  of 5\n",
      "Train on 6376 samples, validate on 1594 samples\n",
      "Epoch 1/5000\n",
      "6376/6376 [==============================] - 1s - loss: 7074.3573 - val_loss: 6326.2687\n",
      "Epoch 2/5000\n",
      "6376/6376 [==============================] - 1s - loss: 6252.8688 - val_loss: 5936.4660\n",
      "Epoch 3/5000\n",
      "6376/6376 [==============================] - 1s - loss: 5922.2066 - val_loss: 5736.1938\n",
      "Epoch 4/5000\n",
      "6376/6376 [==============================] - 1s - loss: 5701.3927 - val_loss: 5498.4865\n",
      "Epoch 5/5000\n",
      "6376/6376 [==============================] - 1s - loss: 5459.7624 - val_loss: 5341.2253\n",
      "Epoch 6/5000\n",
      "6376/6376 [==============================] - 1s - loss: 5241.9286 - val_loss: 5186.6411\n",
      "Epoch 7/5000\n",
      "6376/6376 [==============================] - 1s - loss: 5084.9497 - val_loss: 5130.1899\n",
      "Epoch 8/5000\n",
      "6376/6376 [==============================] - 1s - loss: 4849.9379 - val_loss: 5024.3104\n",
      "Epoch 9/5000\n",
      "6376/6376 [==============================] - 1s - loss: 4695.6715 - val_loss: 4735.3621\n",
      "Epoch 10/5000\n",
      "6376/6376 [==============================] - 1s - loss: 4562.3786 - val_loss: 4477.6466\n",
      "Epoch 11/5000\n",
      "6376/6376 [==============================] - 1s - loss: 4260.8856 - val_loss: 4019.4032\n",
      "Epoch 12/5000\n",
      "6376/6376 [==============================] - 1s - loss: 3760.1831 - val_loss: 3499.7053\n",
      "Epoch 13/5000\n",
      "6376/6376 [==============================] - 1s - loss: 3403.2258 - val_loss: 3376.2191\n",
      "Epoch 14/5000\n",
      "6376/6376 [==============================] - 1s - loss: 3159.1415 - val_loss: 3002.0566\n",
      "Epoch 15/5000\n",
      "6376/6376 [==============================] - 1s - loss: 2968.8565 - val_loss: 2767.4716\n",
      "Epoch 16/5000\n",
      "6376/6376 [==============================] - 1s - loss: 2830.9024 - val_loss: 2638.6354\n",
      "Epoch 17/5000\n",
      "6376/6376 [==============================] - 1s - loss: 2668.3145 - val_loss: 2517.1343\n",
      "Epoch 18/5000\n",
      "6376/6376 [==============================] - 1s - loss: 2625.9668 - val_loss: 2406.1157\n",
      "Epoch 19/5000\n",
      "6376/6376 [==============================] - 1s - loss: 2542.3326 - val_loss: 2304.2267\n",
      "Epoch 20/5000\n",
      "6376/6376 [==============================] - 1s - loss: 2365.4070 - val_loss: 2182.1487\n",
      "Epoch 21/5000\n",
      "6376/6376 [==============================] - 1s - loss: 2261.0684 - val_loss: 2166.9269\n",
      "Epoch 22/5000\n",
      "6376/6376 [==============================] - 1s - loss: 2189.7814 - val_loss: 2043.4003\n",
      "Epoch 23/5000\n",
      "6376/6376 [==============================] - 1s - loss: 2151.0025 - val_loss: 2421.1849\n",
      "Epoch 24/5000\n",
      "6376/6376 [==============================] - 1s - loss: 2024.8516 - val_loss: 2070.3461\n",
      "Epoch 25/5000\n",
      "6376/6376 [==============================] - 1s - loss: 1971.5042 - val_loss: 2018.1638\n",
      "Epoch 26/5000\n",
      "6376/6376 [==============================] - 1s - loss: 1948.7530 - val_loss: 1793.7454\n",
      "Epoch 27/5000\n",
      "6376/6376 [==============================] - 1s - loss: 1844.7047 - val_loss: 1715.3099\n",
      "Epoch 28/5000\n",
      "6376/6376 [==============================] - 1s - loss: 1810.1705 - val_loss: 1745.4739\n",
      "Epoch 29/5000\n",
      "6376/6376 [==============================] - 1s - loss: 1738.0961 - val_loss: 1591.9614\n",
      "Epoch 30/5000\n",
      "6376/6376 [==============================] - 1s - loss: 1740.5593 - val_loss: 1810.0205\n",
      "Epoch 31/5000\n",
      "6376/6376 [==============================] - 1s - loss: 1664.0148 - val_loss: 1640.5797\n",
      "Epoch 32/5000\n",
      "6376/6376 [==============================] - 1s - loss: 1614.9758 - val_loss: 1641.7234\n",
      "Epoch 33/5000\n",
      "6376/6376 [==============================] - 1s - loss: 1582.1190 - val_loss: 1872.7167\n",
      "Epoch 34/5000\n",
      "6376/6376 [==============================] - 1s - loss: 1551.5246 - val_loss: 1451.6470\n",
      "Epoch 35/5000\n",
      "6376/6376 [==============================] - 1s - loss: 1498.0857 - val_loss: 1554.8615\n",
      "Epoch 36/5000\n",
      "6376/6376 [==============================] - 1s - loss: 1465.1846 - val_loss: 1483.4608\n",
      "Epoch 37/5000\n",
      "6376/6376 [==============================] - 1s - loss: 1410.3855 - val_loss: 1407.2041\n",
      "Epoch 38/5000\n",
      "6376/6376 [==============================] - 1s - loss: 1384.4768 - val_loss: 1265.3449\n",
      "Epoch 39/5000\n",
      "6376/6376 [==============================] - 1s - loss: 1350.2217 - val_loss: 1271.2832\n",
      "Epoch 40/5000\n",
      "6376/6376 [==============================] - 1s - loss: 1309.4753 - val_loss: 1247.6766\n",
      "Epoch 41/5000\n",
      "6376/6376 [==============================] - 1s - loss: 1276.8944 - val_loss: 1270.9667\n",
      "Epoch 42/5000\n",
      "6376/6376 [==============================] - 1s - loss: 1263.4131 - val_loss: 1163.0668\n",
      "Epoch 43/5000\n",
      "6376/6376 [==============================] - 1s - loss: 1185.4373 - val_loss: 1319.7843\n",
      "Epoch 44/5000\n",
      "6376/6376 [==============================] - 1s - loss: 1211.2973 - val_loss: 1902.6865\n",
      "Epoch 45/5000\n",
      "6376/6376 [==============================] - 1s - loss: 1185.1472 - val_loss: 1370.9645\n",
      "Epoch 46/5000\n",
      "6376/6376 [==============================] - 1s - loss: 1145.2180 - val_loss: 1232.9036\n",
      "Epoch 47/5000\n",
      "6376/6376 [==============================] - 1s - loss: 1111.1683 - val_loss: 1084.5269\n",
      "Epoch 48/5000\n",
      "6376/6376 [==============================] - 1s - loss: 1118.9394 - val_loss: 1136.2727\n",
      "Epoch 49/5000\n",
      "6376/6376 [==============================] - 1s - loss: 1087.3561 - val_loss: 1071.3811\n",
      "Epoch 50/5000\n",
      "6376/6376 [==============================] - 1s - loss: 1075.1783 - val_loss: 996.3546\n",
      "Epoch 51/5000\n",
      "6376/6376 [==============================] - 1s - loss: 1015.7417 - val_loss: 1080.5079\n",
      "Epoch 52/5000\n",
      "6376/6376 [==============================] - 1s - loss: 1005.0439 - val_loss: 992.4929\n",
      "Epoch 53/5000\n",
      "6376/6376 [==============================] - 1s - loss: 977.1585 - val_loss: 984.3498\n",
      "Epoch 54/5000\n",
      "6376/6376 [==============================] - 1s - loss: 1008.6405 - val_loss: 963.2221\n",
      "Epoch 55/5000\n",
      "6376/6376 [==============================] - 1s - loss: 966.2102 - val_loss: 944.5942\n",
      "Epoch 56/5000\n",
      "6376/6376 [==============================] - 1s - loss: 954.1017 - val_loss: 1069.5613\n",
      "Epoch 57/5000\n",
      "6376/6376 [==============================] - 1s - loss: 930.8303 - val_loss: 990.3235\n",
      "Epoch 58/5000\n",
      "6376/6376 [==============================] - 1s - loss: 910.5118 - val_loss: 937.2039\n",
      "Epoch 59/5000\n",
      "6376/6376 [==============================] - 1s - loss: 895.5227 - val_loss: 918.9284\n",
      "Epoch 60/5000\n",
      "6376/6376 [==============================] - 1s - loss: 886.2943 - val_loss: 873.3220\n",
      "Epoch 61/5000\n",
      "6376/6376 [==============================] - 1s - loss: 860.9056 - val_loss: 930.4654\n",
      "Epoch 62/5000\n",
      "6376/6376 [==============================] - 1s - loss: 881.5115 - val_loss: 1064.6215\n",
      "Epoch 63/5000\n",
      "6376/6376 [==============================] - 1s - loss: 810.1458 - val_loss: 996.9989\n",
      "Epoch 64/5000\n",
      "6376/6376 [==============================] - 1s - loss: 829.7935 - val_loss: 925.3292\n",
      "Epoch 65/5000\n",
      "6376/6376 [==============================] - 1s - loss: 795.7370 - val_loss: 1069.4723\n",
      "Epoch 66/5000\n",
      "6376/6376 [==============================] - 1s - loss: 797.3548 - val_loss: 864.9024\n",
      "Epoch 67/5000\n",
      "6376/6376 [==============================] - 1s - loss: 782.5032 - val_loss: 805.5023\n",
      "Epoch 68/5000\n",
      "6376/6376 [==============================] - 1s - loss: 776.2813 - val_loss: 835.8354\n",
      "Epoch 69/5000\n",
      "6376/6376 [==============================] - 1s - loss: 739.2675 - val_loss: 851.9070\n",
      "Epoch 70/5000\n",
      "6376/6376 [==============================] - 1s - loss: 735.0949 - val_loss: 1105.5931\n",
      "Epoch 71/5000\n",
      "6376/6376 [==============================] - 1s - loss: 724.1290 - val_loss: 751.2340\n",
      "Epoch 72/5000\n",
      "6376/6376 [==============================] - 1s - loss: 708.5031 - val_loss: 806.3498\n",
      "Epoch 73/5000\n",
      "6376/6376 [==============================] - 1s - loss: 689.1486 - val_loss: 791.2708\n",
      "Epoch 74/5000\n",
      "6376/6376 [==============================] - 1s - loss: 675.0915 - val_loss: 713.0057\n",
      "Epoch 75/5000\n",
      "6376/6376 [==============================] - 1s - loss: 652.4491 - val_loss: 750.0436\n",
      "Epoch 76/5000\n",
      "6376/6376 [==============================] - 1s - loss: 664.9289 - val_loss: 772.7469\n",
      "Epoch 77/5000\n",
      "6376/6376 [==============================] - 1s - loss: 634.0803 - val_loss: 818.6956\n",
      "Epoch 78/5000\n",
      "6376/6376 [==============================] - 1s - loss: 631.6479 - val_loss: 734.0195\n",
      "Epoch 79/5000\n",
      "6376/6376 [==============================] - 1s - loss: 621.5081 - val_loss: 712.2247\n",
      "Epoch 80/5000\n",
      "6376/6376 [==============================] - 1s - loss: 631.1255 - val_loss: 680.9083\n",
      "Epoch 81/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6376/6376 [==============================] - 1s - loss: 623.0457 - val_loss: 762.2336\n",
      "Epoch 82/5000\n",
      "6376/6376 [==============================] - 1s - loss: 595.1826 - val_loss: 765.0478\n",
      "Epoch 83/5000\n",
      "6376/6376 [==============================] - 1s - loss: 593.3760 - val_loss: 718.4219\n",
      "Epoch 84/5000\n",
      "6376/6376 [==============================] - 1s - loss: 567.9974 - val_loss: 709.3651\n",
      "Epoch 85/5000\n",
      "6376/6376 [==============================] - 1s - loss: 570.0272 - val_loss: 677.5880\n",
      "Epoch 86/5000\n",
      "6376/6376 [==============================] - 1s - loss: 556.6606 - val_loss: 639.0370\n",
      "Epoch 87/5000\n",
      "6376/6376 [==============================] - 1s - loss: 560.7097 - val_loss: 596.4144\n",
      "Epoch 88/5000\n",
      "6376/6376 [==============================] - 1s - loss: 543.3983 - val_loss: 654.6290\n",
      "Epoch 89/5000\n",
      "6376/6376 [==============================] - 1s - loss: 535.2833 - val_loss: 692.9696\n",
      "Epoch 90/5000\n",
      "6376/6376 [==============================] - 1s - loss: 529.5514 - val_loss: 641.0413\n",
      "Epoch 91/5000\n",
      "6376/6376 [==============================] - 1s - loss: 524.5793 - val_loss: 630.3874\n",
      "Epoch 92/5000\n",
      "6376/6376 [==============================] - 1s - loss: 508.0446 - val_loss: 643.0054\n",
      "Epoch 93/5000\n",
      "6376/6376 [==============================] - 1s - loss: 515.5437 - val_loss: 617.4130\n",
      "Epoch 94/5000\n",
      "6376/6376 [==============================] - 1s - loss: 493.9739 - val_loss: 586.0980\n",
      "Epoch 95/5000\n",
      "6376/6376 [==============================] - 1s - loss: 490.7899 - val_loss: 666.0052\n",
      "Epoch 96/5000\n",
      "6376/6376 [==============================] - 1s - loss: 471.5244 - val_loss: 607.5674\n",
      "Epoch 97/5000\n",
      "6376/6376 [==============================] - 1s - loss: 484.5164 - val_loss: 577.7411\n",
      "Epoch 98/5000\n",
      "6376/6376 [==============================] - 1s - loss: 456.7953 - val_loss: 584.5762\n",
      "Epoch 99/5000\n",
      "6376/6376 [==============================] - 1s - loss: 459.9789 - val_loss: 673.0298\n",
      "Epoch 100/5000\n",
      "6376/6376 [==============================] - 1s - loss: 453.5736 - val_loss: 589.6543\n",
      "Epoch 101/5000\n",
      "6376/6376 [==============================] - 1s - loss: 441.8357 - val_loss: 632.1908\n",
      "Epoch 102/5000\n",
      "6376/6376 [==============================] - 1s - loss: 446.9898 - val_loss: 536.6521\n",
      "Epoch 103/5000\n",
      "6376/6376 [==============================] - 1s - loss: 421.2374 - val_loss: 599.1812\n",
      "Epoch 104/5000\n",
      "6376/6376 [==============================] - 1s - loss: 415.2778 - val_loss: 534.8665\n",
      "Epoch 105/5000\n",
      "6376/6376 [==============================] - 1s - loss: 425.4416 - val_loss: 551.0910\n",
      "Epoch 106/5000\n",
      "6376/6376 [==============================] - 1s - loss: 418.2144 - val_loss: 583.2099\n",
      "Epoch 107/5000\n",
      "6376/6376 [==============================] - 1s - loss: 408.7448 - val_loss: 514.8849\n",
      "Epoch 108/5000\n",
      "6376/6376 [==============================] - 1s - loss: 414.0543 - val_loss: 492.7456\n",
      "Epoch 109/5000\n",
      "6376/6376 [==============================] - 1s - loss: 403.7560 - val_loss: 519.9817\n",
      "Epoch 110/5000\n",
      "6376/6376 [==============================] - 1s - loss: 393.0356 - val_loss: 540.3977\n",
      "Epoch 111/5000\n",
      "6376/6376 [==============================] - 1s - loss: 379.5596 - val_loss: 550.3703\n",
      "Epoch 112/5000\n",
      "6376/6376 [==============================] - 1s - loss: 384.7842 - val_loss: 515.2263\n",
      "Epoch 113/5000\n",
      "6376/6376 [==============================] - 1s - loss: 379.1856 - val_loss: 505.8215\n",
      "Epoch 114/5000\n",
      "6376/6376 [==============================] - 1s - loss: 399.1181 - val_loss: 520.1135\n",
      "Epoch 115/5000\n",
      "6376/6376 [==============================] - 1s - loss: 361.1969 - val_loss: 503.6035\n",
      "Epoch 116/5000\n",
      "6376/6376 [==============================] - 1s - loss: 358.5490 - val_loss: 538.2271\n",
      "Epoch 117/5000\n",
      "6376/6376 [==============================] - 1s - loss: 355.0648 - val_loss: 496.3243\n",
      "Epoch 118/5000\n",
      "6376/6376 [==============================] - 1s - loss: 361.6972 - val_loss: 500.6655\n",
      "Epoch 119/5000\n",
      "6376/6376 [==============================] - 1s - loss: 340.8603 - val_loss: 497.7143\n",
      "Fold:  2  of 5\n",
      "Train on 6376 samples, validate on 1594 samples\n",
      "Epoch 1/5000\n",
      "6376/6376 [==============================] - 1s - loss: 6989.0607 - val_loss: 6757.6784\n",
      "Epoch 2/5000\n",
      "6376/6376 [==============================] - 1s - loss: 6212.7217 - val_loss: 6212.5083\n",
      "Epoch 3/5000\n",
      "6376/6376 [==============================] - 1s - loss: 5882.3807 - val_loss: 5938.2026\n",
      "Epoch 4/5000\n",
      "6376/6376 [==============================] - 1s - loss: 5643.1080 - val_loss: 5700.6328\n",
      "Epoch 5/5000\n",
      "6376/6376 [==============================] - 1s - loss: 5410.1010 - val_loss: 5451.9694\n",
      "Epoch 6/5000\n",
      "6376/6376 [==============================] - 1s - loss: 5142.3873 - val_loss: 5301.1438\n",
      "Epoch 7/5000\n",
      "6376/6376 [==============================] - 1s - loss: 4865.3651 - val_loss: 5066.7150\n",
      "Epoch 8/5000\n",
      "6376/6376 [==============================] - 1s - loss: 4729.2825 - val_loss: 4880.6592\n",
      "Epoch 9/5000\n",
      "6376/6376 [==============================] - 1s - loss: 4552.3488 - val_loss: 4713.5821\n",
      "Epoch 10/5000\n",
      "6376/6376 [==============================] - 1s - loss: 4107.9435 - val_loss: 3844.2387\n",
      "Epoch 11/5000\n",
      "6376/6376 [==============================] - 1s - loss: 3538.0633 - val_loss: 3395.9109\n",
      "Epoch 12/5000\n",
      "6376/6376 [==============================] - 1s - loss: 3246.3176 - val_loss: 3122.7227\n",
      "Epoch 13/5000\n",
      "6376/6376 [==============================] - 1s - loss: 3016.8558 - val_loss: 3443.2890\n",
      "Epoch 14/5000\n",
      "6376/6376 [==============================] - 1s - loss: 2887.8598 - val_loss: 2777.0165\n",
      "Epoch 15/5000\n",
      "6376/6376 [==============================] - 1s - loss: 2732.2027 - val_loss: 2636.2230\n",
      "Epoch 16/5000\n",
      "6376/6376 [==============================] - 1s - loss: 2647.1639 - val_loss: 2533.3964\n",
      "Epoch 17/5000\n",
      "6376/6376 [==============================] - 1s - loss: 2494.7804 - val_loss: 2760.5807\n",
      "Epoch 18/5000\n",
      "6376/6376 [==============================] - 1s - loss: 2385.6802 - val_loss: 2201.6439\n",
      "Epoch 19/5000\n",
      "6376/6376 [==============================] - 1s - loss: 2310.0495 - val_loss: 2553.2425\n",
      "Epoch 20/5000\n",
      "6376/6376 [==============================] - 1s - loss: 2197.4675 - val_loss: 2126.9570\n",
      "Epoch 21/5000\n",
      "6376/6376 [==============================] - 1s - loss: 2132.3501 - val_loss: 2144.2257\n",
      "Epoch 22/5000\n",
      "6376/6376 [==============================] - 1s - loss: 2081.9466 - val_loss: 1936.6076\n",
      "Epoch 23/5000\n",
      "6376/6376 [==============================] - 1s - loss: 2014.4810 - val_loss: 1900.7587\n",
      "Epoch 24/5000\n",
      "6376/6376 [==============================] - 1s - loss: 1987.8757 - val_loss: 1846.4438\n",
      "Epoch 25/5000\n",
      "6376/6376 [==============================] - 1s - loss: 1903.2655 - val_loss: 1794.9884\n",
      "Epoch 26/5000\n",
      "6376/6376 [==============================] - 1s - loss: 1851.5414 - val_loss: 1802.1215\n",
      "Epoch 27/5000\n",
      "6376/6376 [==============================] - 1s - loss: 1782.7162 - val_loss: 1792.8076\n",
      "Epoch 28/5000\n",
      "6376/6376 [==============================] - 1s - loss: 1738.5085 - val_loss: 1627.4500\n",
      "Epoch 29/5000\n",
      "6376/6376 [==============================] - 1s - loss: 1690.9958 - val_loss: 1704.0634\n",
      "Epoch 30/5000\n",
      "6376/6376 [==============================] - 1s - loss: 1611.3247 - val_loss: 1671.7855\n",
      "Epoch 31/5000\n",
      "6376/6376 [==============================] - 1s - loss: 1613.4018 - val_loss: 1479.0249\n",
      "Epoch 32/5000\n",
      "6376/6376 [==============================] - 1s - loss: 1557.1347 - val_loss: 1504.3361\n",
      "Epoch 33/5000\n",
      "6376/6376 [==============================] - 1s - loss: 1555.0905 - val_loss: 1442.6707\n",
      "Epoch 34/5000\n",
      "6376/6376 [==============================] - 1s - loss: 1489.0862 - val_loss: 1440.3231\n",
      "Epoch 35/5000\n",
      "6376/6376 [==============================] - 1s - loss: 1457.1092 - val_loss: 1493.1881\n",
      "Epoch 36/5000\n",
      "6376/6376 [==============================] - 1s - loss: 1418.1529 - val_loss: 1412.2106\n",
      "Epoch 37/5000\n",
      "6376/6376 [==============================] - 1s - loss: 1393.0099 - val_loss: 1319.1986\n",
      "Epoch 38/5000\n",
      "6376/6376 [==============================] - 1s - loss: 1380.8527 - val_loss: 1339.6628\n",
      "Epoch 39/5000\n",
      "6376/6376 [==============================] - 1s - loss: 1372.2399 - val_loss: 1225.3120\n",
      "Epoch 40/5000\n",
      "6376/6376 [==============================] - 1s - loss: 1323.9374 - val_loss: 1299.3816\n",
      "Epoch 41/5000\n",
      "6376/6376 [==============================] - 1s - loss: 1272.8581 - val_loss: 1225.2398\n",
      "Epoch 42/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6376/6376 [==============================] - 1s - loss: 1313.8580 - val_loss: 1166.9857\n",
      "Epoch 43/5000\n",
      "6376/6376 [==============================] - 1s - loss: 1219.3631 - val_loss: 1212.5693\n",
      "Epoch 44/5000\n",
      "6376/6376 [==============================] - 1s - loss: 1237.1828 - val_loss: 1196.3721\n",
      "Epoch 45/5000\n",
      "6376/6376 [==============================] - 1s - loss: 1202.1271 - val_loss: 1149.2777\n",
      "Epoch 46/5000\n",
      "6376/6376 [==============================] - 1s - loss: 1149.5142 - val_loss: 1116.7741\n",
      "Epoch 47/5000\n",
      "6376/6376 [==============================] - 1s - loss: 1142.6054 - val_loss: 1034.4972\n",
      "Epoch 48/5000\n",
      "6376/6376 [==============================] - 1s - loss: 1105.1405 - val_loss: 1363.6066\n",
      "Epoch 49/5000\n",
      "6376/6376 [==============================] - 1s - loss: 1108.7362 - val_loss: 1074.8116\n",
      "Epoch 50/5000\n",
      "6376/6376 [==============================] - 1s - loss: 1109.9890 - val_loss: 1115.6496\n",
      "Epoch 51/5000\n",
      "6376/6376 [==============================] - 1s - loss: 1046.5224 - val_loss: 1037.2477\n",
      "Epoch 52/5000\n",
      "6376/6376 [==============================] - 1s - loss: 1070.8007 - val_loss: 1128.2631\n",
      "Epoch 53/5000\n",
      "6376/6376 [==============================] - 1s - loss: 1023.0230 - val_loss: 1085.0582\n",
      "Epoch 54/5000\n",
      "6376/6376 [==============================] - 1s - loss: 1010.5645 - val_loss: 1110.0646\n",
      "Epoch 55/5000\n",
      "6376/6376 [==============================] - 1s - loss: 1005.4620 - val_loss: 954.6560\n",
      "Epoch 56/5000\n",
      "6376/6376 [==============================] - 1s - loss: 982.6511 - val_loss: 959.7379\n",
      "Epoch 57/5000\n",
      "6376/6376 [==============================] - 1s - loss: 962.7080 - val_loss: 1088.4371\n",
      "Epoch 58/5000\n",
      "6376/6376 [==============================] - 1s - loss: 915.8144 - val_loss: 959.6968\n",
      "Epoch 59/5000\n",
      "6376/6376 [==============================] - 1s - loss: 941.7099 - val_loss: 988.8886\n",
      "Epoch 60/5000\n",
      "6376/6376 [==============================] - 1s - loss: 921.8875 - val_loss: 859.3339\n",
      "Epoch 61/5000\n",
      "6376/6376 [==============================] - 1s - loss: 896.5191 - val_loss: 843.3472\n",
      "Epoch 62/5000\n",
      "6376/6376 [==============================] - 1s - loss: 872.6875 - val_loss: 869.3774\n",
      "Epoch 63/5000\n",
      "6376/6376 [==============================] - 1s - loss: 840.6922 - val_loss: 906.3585\n",
      "Epoch 64/5000\n",
      "6376/6376 [==============================] - 1s - loss: 855.7351 - val_loss: 840.6568\n",
      "Epoch 65/5000\n",
      "6376/6376 [==============================] - 1s - loss: 814.2728 - val_loss: 888.6396\n",
      "Epoch 66/5000\n",
      "6376/6376 [==============================] - 1s - loss: 814.4216 - val_loss: 931.8834\n",
      "Epoch 67/5000\n",
      "6376/6376 [==============================] - 1s - loss: 819.7988 - val_loss: 1005.3877\n",
      "Epoch 68/5000\n",
      "6376/6376 [==============================] - 1s - loss: 784.9175 - val_loss: 766.3526\n",
      "Epoch 69/5000\n",
      "6376/6376 [==============================] - 1s - loss: 788.4956 - val_loss: 816.6278\n",
      "Epoch 70/5000\n",
      "6376/6376 [==============================] - 1s - loss: 771.2444 - val_loss: 762.3083\n",
      "Epoch 71/5000\n",
      "6376/6376 [==============================] - 1s - loss: 749.7669 - val_loss: 724.6329\n",
      "Epoch 72/5000\n",
      "6376/6376 [==============================] - 1s - loss: 730.6664 - val_loss: 810.4183\n",
      "Epoch 73/5000\n",
      "6376/6376 [==============================] - 1s - loss: 737.2479 - val_loss: 735.2722\n",
      "Epoch 74/5000\n",
      "6376/6376 [==============================] - 1s - loss: 723.9046 - val_loss: 719.6530\n",
      "Epoch 75/5000\n",
      "6376/6376 [==============================] - 1s - loss: 729.4170 - val_loss: 671.6002\n",
      "Epoch 76/5000\n",
      "6376/6376 [==============================] - 1s - loss: 695.0595 - val_loss: 807.9363\n",
      "Epoch 77/5000\n",
      "6376/6376 [==============================] - 1s - loss: 688.6136 - val_loss: 666.7687\n",
      "Epoch 78/5000\n",
      "6376/6376 [==============================] - 1s - loss: 674.5082 - val_loss: 670.6490\n",
      "Epoch 79/5000\n",
      "6376/6376 [==============================] - 1s - loss: 646.0146 - val_loss: 653.2621\n",
      "Epoch 80/5000\n",
      "6376/6376 [==============================] - 1s - loss: 652.4946 - val_loss: 642.8250\n",
      "Epoch 81/5000\n",
      "6376/6376 [==============================] - 1s - loss: 641.6432 - val_loss: 625.8627\n",
      "Epoch 82/5000\n",
      "6376/6376 [==============================] - 1s - loss: 621.7598 - val_loss: 618.5375\n",
      "Epoch 83/5000\n",
      "6376/6376 [==============================] - 1s - loss: 640.5216 - val_loss: 605.1658\n",
      "Epoch 84/5000\n",
      "6376/6376 [==============================] - 1s - loss: 593.1800 - val_loss: 589.2790\n",
      "Epoch 85/5000\n",
      "6376/6376 [==============================] - 1s - loss: 631.1812 - val_loss: 602.9935\n",
      "Epoch 86/5000\n",
      "6376/6376 [==============================] - 1s - loss: 586.9241 - val_loss: 565.4480\n",
      "Epoch 87/5000\n",
      "6376/6376 [==============================] - 1s - loss: 604.7347 - val_loss: 608.5976\n",
      "Epoch 88/5000\n",
      "6376/6376 [==============================] - 1s - loss: 568.9272 - val_loss: 657.7475\n",
      "Epoch 89/5000\n",
      "6376/6376 [==============================] - 1s - loss: 565.3393 - val_loss: 569.8588\n",
      "Epoch 90/5000\n",
      "6376/6376 [==============================] - 1s - loss: 571.5706 - val_loss: 589.8526\n",
      "Epoch 91/5000\n",
      "6376/6376 [==============================] - 1s - loss: 546.2093 - val_loss: 644.1179\n",
      "Epoch 92/5000\n",
      "6376/6376 [==============================] - 1s - loss: 529.2419 - val_loss: 562.4970\n",
      "Epoch 93/5000\n",
      "6376/6376 [==============================] - 1s - loss: 541.6436 - val_loss: 606.1394\n",
      "Epoch 94/5000\n",
      "6376/6376 [==============================] - 1s - loss: 536.4308 - val_loss: 681.6748\n",
      "Epoch 95/5000\n",
      "6376/6376 [==============================] - 1s - loss: 505.0440 - val_loss: 528.7916\n",
      "Epoch 96/5000\n",
      "6376/6376 [==============================] - 1s - loss: 512.6348 - val_loss: 597.6276\n",
      "Epoch 97/5000\n",
      "6376/6376 [==============================] - 1s - loss: 496.5743 - val_loss: 578.1631\n",
      "Epoch 98/5000\n",
      "6376/6376 [==============================] - 1s - loss: 502.5608 - val_loss: 577.5124\n",
      "Epoch 99/5000\n",
      "6376/6376 [==============================] - 1s - loss: 472.6843 - val_loss: 548.7117\n",
      "Epoch 100/5000\n",
      "6376/6376 [==============================] - 1s - loss: 478.7009 - val_loss: 537.4843\n",
      "Epoch 101/5000\n",
      "6376/6376 [==============================] - 1s - loss: 474.7827 - val_loss: 544.7846\n",
      "Epoch 102/5000\n",
      "6376/6376 [==============================] - 1s - loss: 452.0347 - val_loss: 549.3260\n",
      "Epoch 103/5000\n",
      "6376/6376 [==============================] - 1s - loss: 453.7737 - val_loss: 538.7238\n",
      "Epoch 104/5000\n",
      "6376/6376 [==============================] - 1s - loss: 444.2666 - val_loss: 504.6034\n",
      "Epoch 105/5000\n",
      "6376/6376 [==============================] - 1s - loss: 459.4191 - val_loss: 526.1531\n",
      "Epoch 106/5000\n",
      "6376/6376 [==============================] - 1s - loss: 444.0972 - val_loss: 508.4066\n",
      "Epoch 107/5000\n",
      "6376/6376 [==============================] - 1s - loss: 429.7968 - val_loss: 513.8142\n",
      "Epoch 108/5000\n",
      "6376/6376 [==============================] - 1s - loss: 417.1554 - val_loss: 507.6343\n",
      "Epoch 109/5000\n",
      "6376/6376 [==============================] - 1s - loss: 410.8908 - val_loss: 458.8184\n",
      "Epoch 110/5000\n",
      "6376/6376 [==============================] - 1s - loss: 422.0185 - val_loss: 491.8676\n",
      "Epoch 111/5000\n",
      "6376/6376 [==============================] - 1s - loss: 412.3803 - val_loss: 462.0896\n",
      "Epoch 112/5000\n",
      "6376/6376 [==============================] - 1s - loss: 394.0064 - val_loss: 510.1080\n",
      "Epoch 113/5000\n",
      "6376/6376 [==============================] - 1s - loss: 402.8195 - val_loss: 564.9823\n",
      "Epoch 114/5000\n",
      "6376/6376 [==============================] - 1s - loss: 399.0998 - val_loss: 439.0138\n",
      "Epoch 115/5000\n",
      "6376/6376 [==============================] - 1s - loss: 387.3137 - val_loss: 453.0335\n",
      "Epoch 116/5000\n",
      "6376/6376 [==============================] - 1s - loss: 383.0719 - val_loss: 437.3283\n",
      "Epoch 117/5000\n",
      "6376/6376 [==============================] - 1s - loss: 390.5023 - val_loss: 448.8280\n",
      "Epoch 118/5000\n",
      "6376/6376 [==============================] - 1s - loss: 381.0995 - val_loss: 438.4808\n",
      "Epoch 119/5000\n",
      "6376/6376 [==============================] - 1s - loss: 376.6411 - val_loss: 421.7414\n",
      "Epoch 120/5000\n",
      "6376/6376 [==============================] - 1s - loss: 357.3719 - val_loss: 441.4754\n",
      "Epoch 121/5000\n",
      "6376/6376 [==============================] - 1s - loss: 372.6849 - val_loss: 430.1426\n",
      "Epoch 122/5000\n",
      "6376/6376 [==============================] - 1s - loss: 362.7081 - val_loss: 450.3406\n",
      "Epoch 123/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6376/6376 [==============================] - 1s - loss: 349.7551 - val_loss: 411.4120\n",
      "Epoch 124/5000\n",
      "6376/6376 [==============================] - 1s - loss: 346.1495 - val_loss: 416.7302\n",
      "Epoch 125/5000\n",
      "6376/6376 [==============================] - 1s - loss: 346.2241 - val_loss: 426.6516\n",
      "Epoch 126/5000\n",
      "6376/6376 [==============================] - 1s - loss: 338.5194 - val_loss: 403.0557\n",
      "Epoch 127/5000\n",
      "6376/6376 [==============================] - 1s - loss: 330.7345 - val_loss: 451.3387\n",
      "Epoch 128/5000\n",
      "6376/6376 [==============================] - 1s - loss: 336.5034 - val_loss: 396.9993\n",
      "Epoch 129/5000\n",
      "6376/6376 [==============================] - 1s - loss: 321.7990 - val_loss: 443.2655\n",
      "Epoch 130/5000\n",
      "6376/6376 [==============================] - 1s - loss: 331.3677 - val_loss: 448.7519\n",
      "Epoch 131/5000\n",
      "6376/6376 [==============================] - 1s - loss: 313.8288 - val_loss: 430.1802\n",
      "Epoch 132/5000\n",
      "6376/6376 [==============================] - 1s - loss: 315.5204 - val_loss: 409.1800\n",
      "Epoch 133/5000\n",
      "6376/6376 [==============================] - 1s - loss: 313.6590 - val_loss: 408.1510\n",
      "Epoch 134/5000\n",
      "6376/6376 [==============================] - 1s - loss: 311.1635 - val_loss: 479.6301\n",
      "Epoch 135/5000\n",
      "6376/6376 [==============================] - 1s - loss: 306.9360 - val_loss: 421.4896\n",
      "Epoch 136/5000\n",
      "6376/6376 [==============================] - 1s - loss: 312.7765 - val_loss: 470.2014\n",
      "Epoch 137/5000\n",
      "6376/6376 [==============================] - 1s - loss: 290.7983 - val_loss: 405.8405\n",
      "Epoch 138/5000\n",
      "6376/6376 [==============================] - 1s - loss: 297.4754 - val_loss: 402.3233\n",
      "Epoch 139/5000\n",
      "6376/6376 [==============================] - 1s - loss: 290.6755 - val_loss: 401.0941\n",
      "Fold:  3  of 5\n",
      "Train on 6376 samples, validate on 1594 samples\n",
      "Epoch 1/5000\n",
      "6376/6376 [==============================] - 1s - loss: 7189.6641 - val_loss: 6419.5168\n",
      "Epoch 2/5000\n",
      "6376/6376 [==============================] - 1s - loss: 6332.4173 - val_loss: 5881.0185\n",
      "Epoch 3/5000\n",
      "6376/6376 [==============================] - 1s - loss: 5964.6016 - val_loss: 5604.0430\n",
      "Epoch 4/5000\n",
      "6376/6376 [==============================] - 1s - loss: 5703.4993 - val_loss: 5444.0895\n",
      "Epoch 5/5000\n",
      "6376/6376 [==============================] - 1s - loss: 5470.4410 - val_loss: 5175.7212\n",
      "Epoch 6/5000\n",
      "6376/6376 [==============================] - 1s - loss: 5239.0202 - val_loss: 5039.5575\n",
      "Epoch 7/5000\n",
      "6376/6376 [==============================] - 1s - loss: 5019.6195 - val_loss: 4902.2887\n",
      "Epoch 8/5000\n",
      "6376/6376 [==============================] - 1s - loss: 4804.2945 - val_loss: 4615.8056\n",
      "Epoch 9/5000\n",
      "6376/6376 [==============================] - 1s - loss: 4566.8972 - val_loss: 4179.9475\n",
      "Epoch 10/5000\n",
      "6376/6376 [==============================] - 1s - loss: 4059.3940 - val_loss: 3532.8276\n",
      "Epoch 11/5000\n",
      "6376/6376 [==============================] - 1s - loss: 3604.0523 - val_loss: 3195.1641\n",
      "Epoch 12/5000\n",
      "6376/6376 [==============================] - 1s - loss: 3383.1129 - val_loss: 3091.1796\n",
      "Epoch 13/5000\n",
      "6376/6376 [==============================] - 1s - loss: 3221.1255 - val_loss: 2931.3907\n",
      "Epoch 14/5000\n",
      "6376/6376 [==============================] - 1s - loss: 2981.4512 - val_loss: 2494.7527\n",
      "Epoch 15/5000\n",
      "6376/6376 [==============================] - 1s - loss: 2862.3329 - val_loss: 2666.3115\n",
      "Epoch 16/5000\n",
      "6376/6376 [==============================] - 1s - loss: 2742.9112 - val_loss: 2355.6761\n",
      "Epoch 17/5000\n",
      "6376/6376 [==============================] - 1s - loss: 2626.5698 - val_loss: 2451.5491\n",
      "Epoch 18/5000\n",
      "6376/6376 [==============================] - 1s - loss: 2545.0507 - val_loss: 2213.0210\n",
      "Epoch 19/5000\n",
      "6376/6376 [==============================] - 1s - loss: 2373.2202 - val_loss: 2066.0050\n",
      "Epoch 20/5000\n",
      "6376/6376 [==============================] - 1s - loss: 2292.9881 - val_loss: 2053.3849\n",
      "Epoch 21/5000\n",
      "6376/6376 [==============================] - 1s - loss: 2194.1806 - val_loss: 2111.8100\n",
      "Epoch 22/5000\n",
      "6376/6376 [==============================] - 1s - loss: 2059.8634 - val_loss: 2190.8714\n",
      "Epoch 23/5000\n",
      "6376/6376 [==============================] - 1s - loss: 2047.0688 - val_loss: 1808.7156\n",
      "Epoch 24/5000\n",
      "6376/6376 [==============================] - 1s - loss: 1989.3787 - val_loss: 1882.1666\n",
      "Epoch 25/5000\n",
      "6376/6376 [==============================] - 1s - loss: 1931.7033 - val_loss: 1655.9323\n",
      "Epoch 26/5000\n",
      "6376/6376 [==============================] - 1s - loss: 1864.1075 - val_loss: 1726.7248\n",
      "Epoch 27/5000\n",
      "6376/6376 [==============================] - 1s - loss: 1846.7938 - val_loss: 1619.6782\n",
      "Epoch 28/5000\n",
      "6376/6376 [==============================] - 1s - loss: 1752.2435 - val_loss: 1481.4143\n",
      "Epoch 29/5000\n",
      "6376/6376 [==============================] - 1s - loss: 1726.6587 - val_loss: 1436.5142\n",
      "Epoch 30/5000\n",
      "6376/6376 [==============================] - 1s - loss: 1689.7103 - val_loss: 1752.7968\n",
      "Epoch 31/5000\n",
      "6376/6376 [==============================] - 1s - loss: 1640.9236 - val_loss: 1570.9818\n",
      "Epoch 32/5000\n",
      "6376/6376 [==============================] - 1s - loss: 1578.1353 - val_loss: 1408.4233\n",
      "Epoch 33/5000\n",
      "6376/6376 [==============================] - 1s - loss: 1545.5868 - val_loss: 1509.7324\n",
      "Epoch 34/5000\n",
      "6376/6376 [==============================] - 1s - loss: 1523.3384 - val_loss: 1313.8707\n",
      "Epoch 35/5000\n",
      "6376/6376 [==============================] - 1s - loss: 1494.9182 - val_loss: 1217.6220\n",
      "Epoch 36/5000\n",
      "6376/6376 [==============================] - 1s - loss: 1467.1942 - val_loss: 1164.8163\n",
      "Epoch 37/5000\n",
      "6376/6376 [==============================] - 1s - loss: 1425.7590 - val_loss: 1215.3148\n",
      "Epoch 38/5000\n",
      "6376/6376 [==============================] - 1s - loss: 1402.3786 - val_loss: 1537.5624\n",
      "Epoch 39/5000\n",
      "6376/6376 [==============================] - 1s - loss: 1367.2212 - val_loss: 1123.1601\n",
      "Epoch 40/5000\n",
      "6376/6376 [==============================] - 1s - loss: 1316.2533 - val_loss: 1164.4129\n",
      "Epoch 41/5000\n",
      "6376/6376 [==============================] - 1s - loss: 1307.4750 - val_loss: 1200.6616\n",
      "Epoch 42/5000\n",
      "6376/6376 [==============================] - 1s - loss: 1272.9016 - val_loss: 1032.4698\n",
      "Epoch 43/5000\n",
      "6376/6376 [==============================] - 1s - loss: 1231.5428 - val_loss: 992.6536\n",
      "Epoch 44/5000\n",
      "6376/6376 [==============================] - 1s - loss: 1246.3093 - val_loss: 996.5066\n",
      "Epoch 45/5000\n",
      "6376/6376 [==============================] - 1s - loss: 1205.6160 - val_loss: 996.2752\n",
      "Epoch 46/5000\n",
      "6376/6376 [==============================] - 1s - loss: 1172.5460 - val_loss: 982.9908\n",
      "Epoch 47/5000\n",
      "6376/6376 [==============================] - 1s - loss: 1133.7444 - val_loss: 980.7493\n",
      "Epoch 48/5000\n",
      "6376/6376 [==============================] - 1s - loss: 1119.5641 - val_loss: 926.6839\n",
      "Epoch 49/5000\n",
      "6376/6376 [==============================] - 1s - loss: 1094.8816 - val_loss: 1449.1669\n",
      "Epoch 50/5000\n",
      "6376/6376 [==============================] - 1s - loss: 1061.1654 - val_loss: 980.4984\n",
      "Epoch 51/5000\n",
      "6376/6376 [==============================] - 1s - loss: 1048.6941 - val_loss: 948.5991\n",
      "Epoch 52/5000\n",
      "6376/6376 [==============================] - 1s - loss: 1027.4749 - val_loss: 936.8488\n",
      "Epoch 53/5000\n",
      "6376/6376 [==============================] - 1s - loss: 1028.2344 - val_loss: 881.4057\n",
      "Epoch 54/5000\n",
      "6376/6376 [==============================] - 1s - loss: 1021.0867 - val_loss: 898.2606\n",
      "Epoch 55/5000\n",
      "6376/6376 [==============================] - 1s - loss: 956.0803 - val_loss: 942.5355\n",
      "Epoch 56/5000\n",
      "6376/6376 [==============================] - 1s - loss: 962.3016 - val_loss: 899.3448\n",
      "Epoch 57/5000\n",
      "6376/6376 [==============================] - 1s - loss: 955.6471 - val_loss: 896.7262\n",
      "Epoch 58/5000\n",
      "6376/6376 [==============================] - 1s - loss: 924.1164 - val_loss: 837.2407\n",
      "Epoch 59/5000\n",
      "6376/6376 [==============================] - 1s - loss: 936.6704 - val_loss: 802.6976\n",
      "Epoch 60/5000\n",
      "6376/6376 [==============================] - 1s - loss: 902.7775 - val_loss: 820.1583\n",
      "Epoch 61/5000\n",
      "6376/6376 [==============================] - 1s - loss: 889.6963 - val_loss: 817.2643\n",
      "Epoch 62/5000\n",
      "6376/6376 [==============================] - 1s - loss: 882.1641 - val_loss: 851.6931\n",
      "Epoch 63/5000\n",
      "6376/6376 [==============================] - 1s - loss: 840.1922 - val_loss: 978.2769\n",
      "Epoch 64/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6376/6376 [==============================] - 1s - loss: 847.7206 - val_loss: 890.6635\n",
      "Epoch 65/5000\n",
      "6376/6376 [==============================] - 1s - loss: 834.5483 - val_loss: 761.5819\n",
      "Epoch 66/5000\n",
      "6376/6376 [==============================] - 1s - loss: 800.1151 - val_loss: 788.6041\n",
      "Epoch 67/5000\n",
      "6376/6376 [==============================] - 1s - loss: 801.8340 - val_loss: 1009.4099\n",
      "Epoch 68/5000\n",
      "6376/6376 [==============================] - 1s - loss: 783.6619 - val_loss: 777.9717\n",
      "Epoch 69/5000\n",
      "6376/6376 [==============================] - 1s - loss: 754.6102 - val_loss: 773.4395\n",
      "Epoch 70/5000\n",
      "6376/6376 [==============================] - 1s - loss: 754.7681 - val_loss: 777.4743\n",
      "Epoch 71/5000\n",
      "6376/6376 [==============================] - 1s - loss: 731.5634 - val_loss: 776.5868\n",
      "Epoch 72/5000\n",
      "6376/6376 [==============================] - 1s - loss: 723.7495 - val_loss: 726.2287\n",
      "Epoch 73/5000\n",
      "6376/6376 [==============================] - 1s - loss: 695.7415 - val_loss: 674.9171\n",
      "Epoch 74/5000\n",
      "6376/6376 [==============================] - 1s - loss: 709.8818 - val_loss: 676.0616\n",
      "Epoch 75/5000\n",
      "6376/6376 [==============================] - 1s - loss: 694.9023 - val_loss: 836.6084\n",
      "Epoch 76/5000\n",
      "6376/6376 [==============================] - 1s - loss: 680.3898 - val_loss: 919.8649\n",
      "Epoch 77/5000\n",
      "6376/6376 [==============================] - 1s - loss: 673.7198 - val_loss: 712.8400\n",
      "Epoch 78/5000\n",
      "6376/6376 [==============================] - 1s - loss: 672.3909 - val_loss: 742.3029\n",
      "Epoch 79/5000\n",
      "6376/6376 [==============================] - 1s - loss: 635.5614 - val_loss: 648.7048\n",
      "Epoch 80/5000\n",
      "6376/6376 [==============================] - 1s - loss: 639.1414 - val_loss: 639.5383\n",
      "Epoch 81/5000\n",
      "6376/6376 [==============================] - 1s - loss: 644.8757 - val_loss: 645.8303\n",
      "Epoch 82/5000\n",
      "6376/6376 [==============================] - 1s - loss: 621.7715 - val_loss: 748.8710\n",
      "Epoch 83/5000\n",
      "6376/6376 [==============================] - 1s - loss: 606.3321 - val_loss: 606.2921\n",
      "Epoch 84/5000\n",
      "6376/6376 [==============================] - 1s - loss: 585.6714 - val_loss: 630.8283\n",
      "Epoch 85/5000\n",
      "6376/6376 [==============================] - 1s - loss: 598.2038 - val_loss: 613.7074\n",
      "Epoch 86/5000\n",
      "6376/6376 [==============================] - 1s - loss: 595.2458 - val_loss: 616.4163\n",
      "Epoch 87/5000\n",
      "6376/6376 [==============================] - 1s - loss: 574.7769 - val_loss: 642.7590\n",
      "Epoch 88/5000\n",
      "6376/6376 [==============================] - 1s - loss: 560.2438 - val_loss: 673.7884\n",
      "Epoch 89/5000\n",
      "6376/6376 [==============================] - 1s - loss: 545.4174 - val_loss: 666.3741\n",
      "Epoch 90/5000\n",
      "6376/6376 [==============================] - 1s - loss: 560.6392 - val_loss: 630.1843\n",
      "Epoch 91/5000\n",
      "6376/6376 [==============================] - 1s - loss: 530.5948 - val_loss: 679.4798\n",
      "Epoch 92/5000\n",
      "6376/6376 [==============================] - 1s - loss: 521.3848 - val_loss: 554.8733\n",
      "Epoch 93/5000\n",
      "6376/6376 [==============================] - 1s - loss: 513.6143 - val_loss: 550.0217\n",
      "Epoch 94/5000\n",
      "6376/6376 [==============================] - 1s - loss: 497.4670 - val_loss: 623.1247\n",
      "Epoch 95/5000\n",
      "6376/6376 [==============================] - 1s - loss: 509.7897 - val_loss: 559.4553\n",
      "Epoch 96/5000\n",
      "6376/6376 [==============================] - 1s - loss: 502.9711 - val_loss: 592.2860\n",
      "Epoch 97/5000\n",
      "6376/6376 [==============================] - 1s - loss: 483.1389 - val_loss: 562.8545\n",
      "Epoch 98/5000\n",
      "6376/6376 [==============================] - 1s - loss: 478.5712 - val_loss: 711.8832\n",
      "Epoch 99/5000\n",
      "6376/6376 [==============================] - 1s - loss: 477.9291 - val_loss: 530.3444\n",
      "Epoch 100/5000\n",
      "6376/6376 [==============================] - 1s - loss: 458.6732 - val_loss: 496.5065\n",
      "Epoch 101/5000\n",
      "6376/6376 [==============================] - 1s - loss: 465.1249 - val_loss: 544.3200\n",
      "Epoch 102/5000\n",
      "6376/6376 [==============================] - 1s - loss: 463.8582 - val_loss: 548.6553\n",
      "Epoch 103/5000\n",
      "6376/6376 [==============================] - 1s - loss: 461.7392 - val_loss: 537.2483\n",
      "Epoch 104/5000\n",
      "6376/6376 [==============================] - 1s - loss: 447.9871 - val_loss: 547.2677\n",
      "Epoch 105/5000\n",
      "6376/6376 [==============================] - 1s - loss: 431.7385 - val_loss: 508.8140\n",
      "Epoch 106/5000\n",
      "6376/6376 [==============================] - 1s - loss: 425.9220 - val_loss: 548.2366\n",
      "Epoch 107/5000\n",
      "6376/6376 [==============================] - 1s - loss: 442.1882 - val_loss: 500.6123\n",
      "Epoch 108/5000\n",
      "6376/6376 [==============================] - 1s - loss: 431.9650 - val_loss: 533.9544\n",
      "Epoch 109/5000\n",
      "6376/6376 [==============================] - 1s - loss: 406.2214 - val_loss: 520.7485\n",
      "Epoch 110/5000\n",
      "6376/6376 [==============================] - 1s - loss: 420.4542 - val_loss: 471.9268\n",
      "Epoch 111/5000\n",
      "6376/6376 [==============================] - 1s - loss: 402.4042 - val_loss: 515.3818\n",
      "Epoch 112/5000\n",
      "6376/6376 [==============================] - 1s - loss: 403.5681 - val_loss: 493.7176\n",
      "Epoch 113/5000\n",
      "6376/6376 [==============================] - 1s - loss: 383.3259 - val_loss: 515.9426\n",
      "Epoch 114/5000\n",
      "6376/6376 [==============================] - 1s - loss: 389.5175 - val_loss: 501.7665\n",
      "Epoch 115/5000\n",
      "6376/6376 [==============================] - 1s - loss: 389.1872 - val_loss: 462.3456\n",
      "Epoch 116/5000\n",
      "6376/6376 [==============================] - 1s - loss: 379.1041 - val_loss: 467.2841\n",
      "Epoch 117/5000\n",
      "6376/6376 [==============================] - 1s - loss: 359.4377 - val_loss: 456.8264\n",
      "Epoch 118/5000\n",
      "6376/6376 [==============================] - 1s - loss: 371.3622 - val_loss: 505.0118\n",
      "Epoch 119/5000\n",
      "6376/6376 [==============================] - 1s - loss: 367.2255 - val_loss: 512.9627\n",
      "Epoch 120/5000\n",
      "6376/6376 [==============================] - 1s - loss: 357.3395 - val_loss: 449.0718\n",
      "Epoch 121/5000\n",
      "6376/6376 [==============================] - 1s - loss: 362.0024 - val_loss: 458.0470\n",
      "Epoch 122/5000\n",
      "6376/6376 [==============================] - 1s - loss: 358.1984 - val_loss: 441.3243\n",
      "Epoch 123/5000\n",
      "6376/6376 [==============================] - 1s - loss: 358.2236 - val_loss: 439.2396\n",
      "Epoch 124/5000\n",
      "6376/6376 [==============================] - 1s - loss: 329.4986 - val_loss: 441.1827\n",
      "Epoch 125/5000\n",
      "6376/6376 [==============================] - 1s - loss: 336.2313 - val_loss: 443.2170\n",
      "Epoch 126/5000\n",
      "6376/6376 [==============================] - 1s - loss: 332.2155 - val_loss: 461.4673\n",
      "Epoch 127/5000\n",
      "6376/6376 [==============================] - 1s - loss: 330.5831 - val_loss: 429.8035\n",
      "Epoch 128/5000\n",
      "6376/6376 [==============================] - 1s - loss: 314.7827 - val_loss: 435.0917\n",
      "Epoch 129/5000\n",
      "6376/6376 [==============================] - 1s - loss: 308.0670 - val_loss: 454.3129\n",
      "Epoch 130/5000\n",
      "6376/6376 [==============================] - 1s - loss: 320.1802 - val_loss: 415.6126\n",
      "Epoch 131/5000\n",
      "6376/6376 [==============================] - 1s - loss: 305.0891 - val_loss: 467.6840\n",
      "Epoch 132/5000\n",
      "6376/6376 [==============================] - 1s - loss: 300.1424 - val_loss: 433.5539\n",
      "Epoch 133/5000\n",
      "6376/6376 [==============================] - 1s - loss: 319.0108 - val_loss: 450.7819\n",
      "Epoch 134/5000\n",
      "6376/6376 [==============================] - 1s - loss: 296.9452 - val_loss: 475.7912\n",
      "Epoch 135/5000\n",
      "6376/6376 [==============================] - 1s - loss: 303.4851 - val_loss: 464.6406\n",
      "Epoch 136/5000\n",
      "6376/6376 [==============================] - 1s - loss: 289.9376 - val_loss: 416.0576\n",
      "Epoch 137/5000\n",
      "6376/6376 [==============================] - 1s - loss: 289.9174 - val_loss: 440.8518\n",
      "Epoch 138/5000\n",
      "6376/6376 [==============================] - 1s - loss: 290.8205 - val_loss: 430.0225\n",
      "Epoch 139/5000\n",
      "6376/6376 [==============================] - 1s - loss: 287.8821 - val_loss: 494.5408\n",
      "Epoch 140/5000\n",
      "6376/6376 [==============================] - 1s - loss: 275.0953 - val_loss: 428.0464\n",
      "Epoch 141/5000\n",
      "6376/6376 [==============================] - 1s - loss: 272.9969 - val_loss: 395.6991\n",
      "Epoch 142/5000\n",
      "6376/6376 [==============================] - 1s - loss: 260.6596 - val_loss: 500.1521\n",
      "Epoch 143/5000\n",
      "6376/6376 [==============================] - 1s - loss: 264.6028 - val_loss: 410.4565\n",
      "Epoch 144/5000\n",
      "6376/6376 [==============================] - 1s - loss: 261.9440 - val_loss: 419.8376\n",
      "Epoch 145/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6376/6376 [==============================] - 1s - loss: 271.8484 - val_loss: 394.1303\n",
      "Epoch 146/5000\n",
      "6376/6376 [==============================] - 1s - loss: 267.9896 - val_loss: 424.1765\n",
      "Epoch 147/5000\n",
      "6376/6376 [==============================] - 1s - loss: 263.7769 - val_loss: 421.8822\n",
      "Epoch 148/5000\n",
      "6376/6376 [==============================] - 1s - loss: 259.7042 - val_loss: 391.7604\n",
      "Epoch 149/5000\n",
      "6376/6376 [==============================] - 1s - loss: 253.0908 - val_loss: 398.3388\n",
      "Epoch 150/5000\n",
      "6376/6376 [==============================] - 1s - loss: 243.7447 - val_loss: 417.2657\n",
      "Epoch 151/5000\n",
      "6376/6376 [==============================] - 1s - loss: 247.7864 - val_loss: 397.3574\n",
      "Epoch 152/5000\n",
      "6376/6376 [==============================] - 1s - loss: 240.4183 - val_loss: 417.9129\n",
      "Epoch 153/5000\n",
      "6376/6376 [==============================] - 1s - loss: 248.3806 - val_loss: 372.0916\n",
      "Epoch 154/5000\n",
      "6376/6376 [==============================] - 1s - loss: 246.3979 - val_loss: 391.5662\n",
      "Epoch 155/5000\n",
      "6376/6376 [==============================] - 1s - loss: 239.6386 - val_loss: 367.5015\n",
      "Epoch 156/5000\n",
      "6376/6376 [==============================] - 1s - loss: 244.6308 - val_loss: 421.6613\n",
      "Epoch 157/5000\n",
      "6376/6376 [==============================] - 1s - loss: 228.8170 - val_loss: 429.1886\n",
      "Epoch 158/5000\n",
      "6376/6376 [==============================] - 1s - loss: 229.3870 - val_loss: 419.6693\n",
      "Epoch 159/5000\n",
      "6376/6376 [==============================] - 1s - loss: 231.5867 - val_loss: 371.6460\n",
      "Epoch 160/5000\n",
      "6376/6376 [==============================] - 1s - loss: 222.0382 - val_loss: 390.7802\n",
      "Epoch 161/5000\n",
      "6376/6376 [==============================] - 1s - loss: 226.9209 - val_loss: 388.0000\n",
      "Epoch 162/5000\n",
      "6376/6376 [==============================] - 1s - loss: 214.3447 - val_loss: 367.8009\n",
      "Epoch 163/5000\n",
      "6376/6376 [==============================] - 1s - loss: 213.4794 - val_loss: 371.0437\n",
      "Epoch 164/5000\n",
      "6376/6376 [==============================] - 1s - loss: 219.7849 - val_loss: 357.4381\n",
      "Epoch 165/5000\n",
      "6376/6376 [==============================] - 1s - loss: 216.4740 - val_loss: 435.5824\n",
      "Epoch 166/5000\n",
      "6376/6376 [==============================] - 1s - loss: 214.5087 - val_loss: 375.5613\n",
      "Epoch 167/5000\n",
      "6376/6376 [==============================] - 1s - loss: 211.0456 - val_loss: 355.0747\n",
      "Epoch 168/5000\n",
      "6376/6376 [==============================] - 1s - loss: 213.6034 - val_loss: 377.6483\n",
      "Epoch 169/5000\n",
      "6376/6376 [==============================] - 1s - loss: 211.7371 - val_loss: 380.3503\n",
      "Epoch 170/5000\n",
      "6376/6376 [==============================] - 1s - loss: 207.4251 - val_loss: 365.4585\n",
      "Epoch 171/5000\n",
      "6376/6376 [==============================] - 1s - loss: 209.8596 - val_loss: 374.4684\n",
      "Epoch 172/5000\n",
      "6376/6376 [==============================] - 1s - loss: 196.8685 - val_loss: 349.6453\n",
      "Epoch 173/5000\n",
      "6376/6376 [==============================] - 1s - loss: 204.0903 - val_loss: 366.6436\n",
      "Epoch 174/5000\n",
      "6376/6376 [==============================] - 1s - loss: 201.1734 - val_loss: 376.0552\n",
      "Epoch 175/5000\n",
      "6376/6376 [==============================] - 1s - loss: 191.3553 - val_loss: 344.4718\n",
      "Epoch 176/5000\n",
      "6376/6376 [==============================] - 1s - loss: 193.4528 - val_loss: 353.8617\n",
      "Epoch 177/5000\n",
      "6376/6376 [==============================] - 1s - loss: 199.3602 - val_loss: 388.1585\n",
      "Epoch 178/5000\n",
      "6376/6376 [==============================] - 1s - loss: 191.9780 - val_loss: 362.0296\n",
      "Epoch 179/5000\n",
      "6376/6376 [==============================] - 1s - loss: 185.8087 - val_loss: 397.6930\n",
      "Epoch 180/5000\n",
      "6376/6376 [==============================] - 1s - loss: 181.6720 - val_loss: 383.2186\n",
      "Epoch 181/5000\n",
      "6376/6376 [==============================] - 1s - loss: 181.3119 - val_loss: 364.1676\n",
      "Epoch 182/5000\n",
      "6376/6376 [==============================] - 1s - loss: 190.2252 - val_loss: 344.0626\n",
      "Epoch 183/5000\n",
      "6376/6376 [==============================] - 1s - loss: 186.4764 - val_loss: 351.7148\n",
      "Epoch 184/5000\n",
      "6376/6376 [==============================] - 1s - loss: 179.4788 - val_loss: 347.7392\n",
      "Epoch 185/5000\n",
      "6376/6376 [==============================] - 1s - loss: 177.3883 - val_loss: 358.0985\n",
      "Epoch 186/5000\n",
      "6376/6376 [==============================] - 1s - loss: 181.0713 - val_loss: 352.3663\n",
      "Epoch 187/5000\n",
      "6376/6376 [==============================] - 1s - loss: 181.3187 - val_loss: 369.9263\n",
      "Epoch 188/5000\n",
      "6376/6376 [==============================] - 1s - loss: 180.9839 - val_loss: 342.8805\n",
      "Epoch 189/5000\n",
      "6376/6376 [==============================] - 1s - loss: 168.7756 - val_loss: 340.7392\n",
      "Epoch 190/5000\n",
      "6376/6376 [==============================] - 1s - loss: 170.9039 - val_loss: 354.0307\n",
      "Epoch 191/5000\n",
      "6376/6376 [==============================] - 1s - loss: 165.9626 - val_loss: 373.4609\n",
      "Epoch 192/5000\n",
      "6376/6376 [==============================] - 1s - loss: 167.9308 - val_loss: 341.2146\n",
      "Epoch 193/5000\n",
      "6376/6376 [==============================] - 1s - loss: 165.6325 - val_loss: 365.1704\n",
      "Epoch 194/5000\n",
      "6376/6376 [==============================] - 1s - loss: 168.6669 - val_loss: 340.7186\n",
      "Epoch 195/5000\n",
      "6376/6376 [==============================] - 1s - loss: 166.4057 - val_loss: 354.3873\n",
      "Epoch 196/5000\n",
      "6376/6376 [==============================] - 1s - loss: 165.2855 - val_loss: 354.3289\n",
      "Epoch 197/5000\n",
      "6376/6376 [==============================] - 1s - loss: 159.7432 - val_loss: 344.2385\n",
      "Epoch 198/5000\n",
      "6376/6376 [==============================] - 1s - loss: 155.2485 - val_loss: 392.5428\n",
      "Epoch 199/5000\n",
      "6376/6376 [==============================] - 1s - loss: 157.9175 - val_loss: 350.4564\n",
      "Epoch 200/5000\n",
      "6376/6376 [==============================] - 1s - loss: 155.2162 - val_loss: 368.7393\n",
      "Epoch 201/5000\n",
      "6376/6376 [==============================] - 1s - loss: 152.4938 - val_loss: 360.3569\n",
      "Epoch 202/5000\n",
      "6376/6376 [==============================] - 1s - loss: 155.8962 - val_loss: 335.9586\n",
      "Epoch 203/5000\n",
      "6376/6376 [==============================] - 1s - loss: 160.0725 - val_loss: 354.5744\n",
      "Epoch 204/5000\n",
      "6376/6376 [==============================] - 1s - loss: 157.8430 - val_loss: 343.2136\n",
      "Epoch 205/5000\n",
      "6376/6376 [==============================] - 1s - loss: 153.8018 - val_loss: 340.7243\n",
      "Epoch 206/5000\n",
      "6376/6376 [==============================] - 1s - loss: 143.6735 - val_loss: 346.2900\n",
      "Epoch 207/5000\n",
      "6376/6376 [==============================] - 1s - loss: 153.1909 - val_loss: 331.2702\n",
      "Epoch 208/5000\n",
      "6376/6376 [==============================] - 1s - loss: 156.6151 - val_loss: 333.2440\n",
      "Epoch 209/5000\n",
      "6376/6376 [==============================] - 1s - loss: 144.0422 - val_loss: 348.1313\n",
      "Epoch 210/5000\n",
      "6376/6376 [==============================] - 1s - loss: 150.7975 - val_loss: 332.4466\n",
      "Epoch 211/5000\n",
      "6376/6376 [==============================] - 1s - loss: 142.7788 - val_loss: 324.5817\n",
      "Epoch 212/5000\n",
      "6376/6376 [==============================] - 1s - loss: 147.1540 - val_loss: 327.3267\n",
      "Epoch 213/5000\n",
      "6376/6376 [==============================] - 1s - loss: 144.3541 - val_loss: 316.4756\n",
      "Epoch 214/5000\n",
      "6376/6376 [==============================] - 1s - loss: 139.0359 - val_loss: 322.4041\n",
      "Epoch 215/5000\n",
      "6376/6376 [==============================] - 1s - loss: 136.5700 - val_loss: 315.7294\n",
      "Epoch 216/5000\n",
      "6376/6376 [==============================] - 1s - loss: 139.1644 - val_loss: 332.2209\n",
      "Epoch 217/5000\n",
      "6376/6376 [==============================] - 1s - loss: 134.9880 - val_loss: 323.5140\n",
      "Epoch 218/5000\n",
      "6376/6376 [==============================] - 1s - loss: 137.1196 - val_loss: 331.6221\n",
      "Epoch 219/5000\n",
      "6376/6376 [==============================] - 1s - loss: 132.9057 - val_loss: 313.8713\n",
      "Epoch 220/5000\n",
      "6376/6376 [==============================] - 1s - loss: 131.9958 - val_loss: 356.6828\n",
      "Epoch 221/5000\n",
      "6376/6376 [==============================] - 1s - loss: 135.0155 - val_loss: 323.1938\n",
      "Epoch 222/5000\n",
      "6376/6376 [==============================] - 1s - loss: 132.1244 - val_loss: 326.2323\n",
      "Epoch 223/5000\n",
      "6376/6376 [==============================] - 1s - loss: 130.1131 - val_loss: 308.6781\n",
      "Epoch 224/5000\n",
      "6376/6376 [==============================] - 1s - loss: 129.1690 - val_loss: 328.6654\n",
      "Epoch 225/5000\n",
      "6376/6376 [==============================] - 1s - loss: 130.7355 - val_loss: 321.6790\n",
      "Epoch 226/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6376/6376 [==============================] - 1s - loss: 130.0618 - val_loss: 338.7296\n",
      "Epoch 227/5000\n",
      "6376/6376 [==============================] - 1s - loss: 125.6934 - val_loss: 324.7931\n",
      "Epoch 228/5000\n",
      "6376/6376 [==============================] - 1s - loss: 126.7453 - val_loss: 308.9785\n",
      "Epoch 229/5000\n",
      "6376/6376 [==============================] - 1s - loss: 123.2547 - val_loss: 316.8067\n",
      "Epoch 230/5000\n",
      "6376/6376 [==============================] - 1s - loss: 125.7356 - val_loss: 314.1241\n",
      "Epoch 231/5000\n",
      "6376/6376 [==============================] - 1s - loss: 122.2621 - val_loss: 314.7761\n",
      "Epoch 232/5000\n",
      "6376/6376 [==============================] - 1s - loss: 121.6727 - val_loss: 306.4419\n",
      "Epoch 233/5000\n",
      "6376/6376 [==============================] - 1s - loss: 124.9012 - val_loss: 317.6299\n",
      "Epoch 234/5000\n",
      "6376/6376 [==============================] - 1s - loss: 120.4619 - val_loss: 320.1627\n",
      "Epoch 235/5000\n",
      "6376/6376 [==============================] - 1s - loss: 123.7247 - val_loss: 324.1892\n",
      "Epoch 236/5000\n",
      "6376/6376 [==============================] - 1s - loss: 118.1965 - val_loss: 332.8978\n",
      "Epoch 237/5000\n",
      "6376/6376 [==============================] - 1s - loss: 118.7780 - val_loss: 299.3647\n",
      "Epoch 238/5000\n",
      "6376/6376 [==============================] - 1s - loss: 118.2732 - val_loss: 340.4651\n",
      "Epoch 239/5000\n",
      "6376/6376 [==============================] - 1s - loss: 121.4378 - val_loss: 310.8387\n",
      "Epoch 240/5000\n",
      "6376/6376 [==============================] - 1s - loss: 119.5685 - val_loss: 309.7218\n",
      "Epoch 241/5000\n",
      "6376/6376 [==============================] - 1s - loss: 110.6505 - val_loss: 294.4781\n",
      "Epoch 242/5000\n",
      "6376/6376 [==============================] - 1s - loss: 113.1646 - val_loss: 303.1749\n",
      "Epoch 243/5000\n",
      "6376/6376 [==============================] - 1s - loss: 116.6026 - val_loss: 319.4646\n",
      "Epoch 244/5000\n",
      "6376/6376 [==============================] - 1s - loss: 110.3912 - val_loss: 303.1277\n",
      "Epoch 245/5000\n",
      "6376/6376 [==============================] - 1s - loss: 110.2423 - val_loss: 310.0945\n",
      "Epoch 246/5000\n",
      "6376/6376 [==============================] - 1s - loss: 115.0411 - val_loss: 309.3358\n",
      "Epoch 247/5000\n",
      "6376/6376 [==============================] - 1s - loss: 112.9629 - val_loss: 343.3600\n",
      "Epoch 248/5000\n",
      "6376/6376 [==============================] - 1s - loss: 110.0518 - val_loss: 321.7864\n",
      "Epoch 249/5000\n",
      "6376/6376 [==============================] - 1s - loss: 111.3717 - val_loss: 307.9042\n",
      "Epoch 250/5000\n",
      "6376/6376 [==============================] - 1s - loss: 107.5532 - val_loss: 309.0561\n",
      "Epoch 251/5000\n",
      "6376/6376 [==============================] - 1s - loss: 111.4242 - val_loss: 304.0149\n",
      "Epoch 252/5000\n",
      "6376/6376 [==============================] - 1s - loss: 109.4010 - val_loss: 324.1777\n",
      "Fold:  4  of 5\n",
      "Train on 6376 samples, validate on 1594 samples\n",
      "Epoch 1/5000\n",
      "6376/6376 [==============================] - 1s - loss: 7099.1300 - val_loss: 6595.6766\n",
      "Epoch 2/5000\n",
      "6376/6376 [==============================] - 1s - loss: 6214.7210 - val_loss: 6068.6237\n",
      "Epoch 3/5000\n",
      "6376/6376 [==============================] - 1s - loss: 5871.4068 - val_loss: 5874.6022\n",
      "Epoch 4/5000\n",
      "6376/6376 [==============================] - 1s - loss: 5674.8905 - val_loss: 5661.6376\n",
      "Epoch 5/5000\n",
      "6376/6376 [==============================] - 1s - loss: 5468.3696 - val_loss: 5402.9924\n",
      "Epoch 6/5000\n",
      "6376/6376 [==============================] - 1s - loss: 5237.9055 - val_loss: 5169.9049\n",
      "Epoch 7/5000\n",
      "6376/6376 [==============================] - 1s - loss: 5035.4718 - val_loss: 5147.9167\n",
      "Epoch 8/5000\n",
      "6376/6376 [==============================] - 1s - loss: 4861.4709 - val_loss: 4731.9292\n",
      "Epoch 9/5000\n",
      "6376/6376 [==============================] - 1s - loss: 4684.1382 - val_loss: 4676.5196\n",
      "Epoch 10/5000\n",
      "6376/6376 [==============================] - 1s - loss: 4487.5760 - val_loss: 4325.9434\n",
      "Epoch 11/5000\n",
      "6376/6376 [==============================] - 1s - loss: 3937.2717 - val_loss: 3931.0842\n",
      "Epoch 12/5000\n",
      "6376/6376 [==============================] - 1s - loss: 3563.2224 - val_loss: 3665.8847\n",
      "Epoch 13/5000\n",
      "6376/6376 [==============================] - 1s - loss: 3343.2111 - val_loss: 3395.8780\n",
      "Epoch 14/5000\n",
      "6376/6376 [==============================] - 1s - loss: 3194.6911 - val_loss: 3430.1206\n",
      "Epoch 15/5000\n",
      "6376/6376 [==============================] - 1s - loss: 2987.0525 - val_loss: 3040.4307\n",
      "Epoch 16/5000\n",
      "6376/6376 [==============================] - 1s - loss: 2884.8949 - val_loss: 3138.6280\n",
      "Epoch 17/5000\n",
      "6376/6376 [==============================] - 1s - loss: 2730.1351 - val_loss: 3168.2799\n",
      "Epoch 18/5000\n",
      "6376/6376 [==============================] - 1s - loss: 2630.3308 - val_loss: 2775.5606\n",
      "Epoch 19/5000\n",
      "6376/6376 [==============================] - 1s - loss: 2485.6140 - val_loss: 2772.8351\n",
      "Epoch 20/5000\n",
      "6376/6376 [==============================] - 1s - loss: 2377.2116 - val_loss: 2634.1735\n",
      "Epoch 21/5000\n",
      "6376/6376 [==============================] - 1s - loss: 2362.8435 - val_loss: 2702.6379\n",
      "Epoch 22/5000\n",
      "6376/6376 [==============================] - 1s - loss: 2234.7375 - val_loss: 2620.6904\n",
      "Epoch 23/5000\n",
      "6376/6376 [==============================] - 1s - loss: 2137.4312 - val_loss: 2289.6548\n",
      "Epoch 24/5000\n",
      "6376/6376 [==============================] - 1s - loss: 2109.2335 - val_loss: 2246.0683\n",
      "Epoch 25/5000\n",
      "6376/6376 [==============================] - 1s - loss: 2050.4019 - val_loss: 2226.2430\n",
      "Epoch 26/5000\n",
      "6376/6376 [==============================] - 1s - loss: 2008.1814 - val_loss: 2204.8095\n",
      "Epoch 27/5000\n",
      "6376/6376 [==============================] - 1s - loss: 1925.3596 - val_loss: 2240.7422\n",
      "Epoch 28/5000\n",
      "6376/6376 [==============================] - 1s - loss: 1795.2744 - val_loss: 2034.2709\n",
      "Epoch 29/5000\n",
      "6376/6376 [==============================] - 1s - loss: 1770.2004 - val_loss: 2149.0141\n",
      "Epoch 30/5000\n",
      "6376/6376 [==============================] - 1s - loss: 1715.6693 - val_loss: 1961.7774\n",
      "Epoch 31/5000\n",
      "6376/6376 [==============================] - 1s - loss: 1702.8736 - val_loss: 1925.4365\n",
      "Epoch 32/5000\n",
      "6376/6376 [==============================] - 1s - loss: 1594.3185 - val_loss: 2010.3138\n",
      "Epoch 33/5000\n",
      "6376/6376 [==============================] - 1s - loss: 1548.5388 - val_loss: 1736.3837\n",
      "Epoch 34/5000\n",
      "6376/6376 [==============================] - 1s - loss: 1506.8854 - val_loss: 2421.1736\n",
      "Epoch 35/5000\n",
      "6376/6376 [==============================] - 1s - loss: 1463.5347 - val_loss: 1752.5037\n",
      "Epoch 36/5000\n",
      "6376/6376 [==============================] - 1s - loss: 1446.5727 - val_loss: 1632.7239\n",
      "Epoch 37/5000\n",
      "6376/6376 [==============================] - 1s - loss: 1386.3379 - val_loss: 1679.3223\n",
      "Epoch 38/5000\n",
      "6376/6376 [==============================] - 1s - loss: 1363.7618 - val_loss: 1601.4207\n",
      "Epoch 39/5000\n",
      "6376/6376 [==============================] - 1s - loss: 1361.9940 - val_loss: 1505.4791\n",
      "Epoch 40/5000\n",
      "6376/6376 [==============================] - 1s - loss: 1280.1501 - val_loss: 1622.4170\n",
      "Epoch 41/5000\n",
      "6376/6376 [==============================] - 1s - loss: 1267.3768 - val_loss: 1863.4635\n",
      "Epoch 42/5000\n",
      "6376/6376 [==============================] - 1s - loss: 1240.4871 - val_loss: 1396.7013\n",
      "Epoch 43/5000\n",
      "6376/6376 [==============================] - 1s - loss: 1200.2119 - val_loss: 1593.1072\n",
      "Epoch 44/5000\n",
      "6376/6376 [==============================] - 1s - loss: 1204.4724 - val_loss: 2142.2661\n",
      "Epoch 45/5000\n",
      "6376/6376 [==============================] - 1s - loss: 1161.6855 - val_loss: 1324.1747\n",
      "Epoch 46/5000\n",
      "6376/6376 [==============================] - 1s - loss: 1124.9130 - val_loss: 1489.2935\n",
      "Epoch 47/5000\n",
      "6376/6376 [==============================] - 1s - loss: 1123.6745 - val_loss: 1408.1300\n",
      "Epoch 48/5000\n",
      "6376/6376 [==============================] - 1s - loss: 1043.2591 - val_loss: 1371.3827\n",
      "Epoch 49/5000\n",
      "6376/6376 [==============================] - 1s - loss: 1076.6446 - val_loss: 1350.1485\n",
      "Epoch 50/5000\n",
      "6376/6376 [==============================] - 1s - loss: 1020.8200 - val_loss: 1284.6910\n",
      "Epoch 51/5000\n",
      "6376/6376 [==============================] - 1s - loss: 1000.2167 - val_loss: 1498.1754\n",
      "Epoch 52/5000\n",
      "6376/6376 [==============================] - 1s - loss: 998.4206 - val_loss: 1468.1066\n",
      "Epoch 53/5000\n",
      "6376/6376 [==============================] - 1s - loss: 990.7646 - val_loss: 1255.5047\n",
      "Epoch 54/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6376/6376 [==============================] - 1s - loss: 972.1506 - val_loss: 1220.0270\n",
      "Epoch 55/5000\n",
      "6376/6376 [==============================] - 1s - loss: 953.3509 - val_loss: 1745.2812\n",
      "Epoch 56/5000\n",
      "6376/6376 [==============================] - 1s - loss: 937.5432 - val_loss: 1206.2614\n",
      "Epoch 57/5000\n",
      "6376/6376 [==============================] - 1s - loss: 895.8067 - val_loss: 1290.4827\n",
      "Epoch 58/5000\n",
      "6376/6376 [==============================] - 1s - loss: 927.8747 - val_loss: 1181.8282\n",
      "Epoch 59/5000\n",
      "6376/6376 [==============================] - 1s - loss: 890.9855 - val_loss: 1376.7357\n",
      "Epoch 60/5000\n",
      "6376/6376 [==============================] - 1s - loss: 875.8122 - val_loss: 1146.2920\n",
      "Epoch 61/5000\n",
      "6376/6376 [==============================] - 1s - loss: 837.7650 - val_loss: 1183.1611\n",
      "Epoch 62/5000\n",
      "6376/6376 [==============================] - 1s - loss: 808.7305 - val_loss: 1121.0349\n",
      "Epoch 63/5000\n",
      "6376/6376 [==============================] - 1s - loss: 795.1458 - val_loss: 1234.2756\n",
      "Epoch 64/5000\n",
      "6376/6376 [==============================] - 1s - loss: 785.8882 - val_loss: 1113.5156\n",
      "Epoch 65/5000\n",
      "6376/6376 [==============================] - 1s - loss: 805.6318 - val_loss: 1098.7040\n",
      "Epoch 66/5000\n",
      "6376/6376 [==============================] - 1s - loss: 783.0538 - val_loss: 1031.1506\n",
      "Epoch 67/5000\n",
      "6376/6376 [==============================] - 1s - loss: 764.9761 - val_loss: 1205.0489\n",
      "Epoch 68/5000\n",
      "6376/6376 [==============================] - 1s - loss: 755.7947 - val_loss: 1016.4987\n",
      "Epoch 69/5000\n",
      "6376/6376 [==============================] - 1s - loss: 715.5649 - val_loss: 1512.8622\n",
      "Epoch 70/5000\n",
      "6376/6376 [==============================] - 1s - loss: 717.1302 - val_loss: 1242.7581\n",
      "Epoch 71/5000\n",
      "6376/6376 [==============================] - 1s - loss: 674.3870 - val_loss: 1072.2073\n",
      "Epoch 72/5000\n",
      "6376/6376 [==============================] - 1s - loss: 705.0785 - val_loss: 1040.1579\n",
      "Epoch 73/5000\n",
      "6376/6376 [==============================] - 1s - loss: 680.7594 - val_loss: 1198.3351\n",
      "Epoch 74/5000\n",
      "6376/6376 [==============================] - 1s - loss: 673.6807 - val_loss: 1003.6786\n",
      "Epoch 75/5000\n",
      "6376/6376 [==============================] - 1s - loss: 680.3775 - val_loss: 1119.4392\n",
      "Epoch 76/5000\n",
      "6376/6376 [==============================] - 1s - loss: 654.8989 - val_loss: 963.7109\n",
      "Epoch 77/5000\n",
      "6376/6376 [==============================] - 1s - loss: 649.2772 - val_loss: 944.9487\n",
      "Epoch 78/5000\n",
      "6376/6376 [==============================] - 1s - loss: 622.9785 - val_loss: 955.7535\n",
      "Epoch 79/5000\n",
      "6376/6376 [==============================] - 1s - loss: 616.8583 - val_loss: 962.2879\n",
      "Epoch 80/5000\n",
      "6376/6376 [==============================] - 1s - loss: 626.7491 - val_loss: 936.2962\n",
      "Epoch 81/5000\n",
      "6376/6376 [==============================] - 1s - loss: 598.9933 - val_loss: 1023.0995\n",
      "Epoch 82/5000\n",
      "6376/6376 [==============================] - 1s - loss: 598.2725 - val_loss: 922.3500\n",
      "Epoch 83/5000\n",
      "6376/6376 [==============================] - 1s - loss: 591.8814 - val_loss: 885.2660\n",
      "Epoch 84/5000\n",
      "6376/6376 [==============================] - 1s - loss: 562.5836 - val_loss: 893.0650\n",
      "Epoch 85/5000\n",
      "6376/6376 [==============================] - 1s - loss: 573.3737 - val_loss: 881.6429\n",
      "Epoch 86/5000\n",
      "6376/6376 [==============================] - 1s - loss: 547.0659 - val_loss: 1018.5394\n",
      "Epoch 87/5000\n",
      "6376/6376 [==============================] - 1s - loss: 543.1380 - val_loss: 882.7521\n",
      "Epoch 88/5000\n",
      "6376/6376 [==============================] - 1s - loss: 548.3564 - val_loss: 899.0936\n",
      "Epoch 89/5000\n",
      "6376/6376 [==============================] - 1s - loss: 538.9234 - val_loss: 901.8729\n",
      "Epoch 90/5000\n",
      "6376/6376 [==============================] - 1s - loss: 526.6202 - val_loss: 1034.1268\n",
      "Epoch 91/5000\n",
      "6376/6376 [==============================] - 1s - loss: 516.6908 - val_loss: 862.5779\n",
      "Epoch 92/5000\n",
      "6376/6376 [==============================] - 1s - loss: 509.2923 - val_loss: 946.5668\n",
      "Epoch 93/5000\n",
      "6376/6376 [==============================] - 1s - loss: 513.3781 - val_loss: 847.4251\n",
      "Epoch 94/5000\n",
      "6376/6376 [==============================] - 1s - loss: 491.1823 - val_loss: 892.5260\n",
      "Epoch 95/5000\n",
      "6376/6376 [==============================] - 1s - loss: 487.5465 - val_loss: 908.4509\n",
      "Epoch 96/5000\n",
      "6376/6376 [==============================] - 1s - loss: 482.3614 - val_loss: 894.7098\n",
      "Epoch 97/5000\n",
      "6376/6376 [==============================] - 1s - loss: 476.6434 - val_loss: 883.1225\n",
      "Epoch 98/5000\n",
      "6376/6376 [==============================] - 1s - loss: 463.2076 - val_loss: 918.3161\n",
      "Epoch 99/5000\n",
      "6376/6376 [==============================] - 1s - loss: 452.1615 - val_loss: 844.2435\n",
      "Epoch 100/5000\n",
      "6376/6376 [==============================] - 1s - loss: 466.6827 - val_loss: 880.7019\n",
      "Epoch 101/5000\n",
      "6376/6376 [==============================] - 1s - loss: 426.5349 - val_loss: 907.2497\n",
      "Epoch 102/5000\n",
      "6376/6376 [==============================] - 1s - loss: 444.3898 - val_loss: 913.4395\n",
      "Epoch 103/5000\n",
      "6376/6376 [==============================] - 1s - loss: 448.6091 - val_loss: 933.6714\n",
      "Epoch 104/5000\n",
      "6376/6376 [==============================] - 1s - loss: 432.8868 - val_loss: 813.9675\n",
      "Epoch 105/5000\n",
      "6376/6376 [==============================] - 1s - loss: 422.9673 - val_loss: 827.0819\n",
      "Epoch 106/5000\n",
      "6376/6376 [==============================] - 1s - loss: 418.8061 - val_loss: 781.8457\n",
      "Epoch 107/5000\n",
      "6376/6376 [==============================] - 1s - loss: 406.8855 - val_loss: 765.7865\n",
      "Epoch 108/5000\n",
      "6376/6376 [==============================] - 1s - loss: 423.8353 - val_loss: 748.1965\n",
      "Epoch 109/5000\n",
      "6376/6376 [==============================] - 1s - loss: 409.1385 - val_loss: 780.1842\n",
      "Epoch 110/5000\n",
      "6376/6376 [==============================] - 1s - loss: 389.6900 - val_loss: 934.0288\n",
      "Epoch 111/5000\n",
      "6376/6376 [==============================] - 1s - loss: 391.9916 - val_loss: 791.6815\n",
      "Epoch 112/5000\n",
      "6376/6376 [==============================] - 1s - loss: 385.3402 - val_loss: 756.2555\n",
      "Epoch 113/5000\n",
      "6376/6376 [==============================] - 1s - loss: 391.0117 - val_loss: 825.3956\n",
      "Epoch 114/5000\n",
      "6376/6376 [==============================] - 1s - loss: 380.7165 - val_loss: 805.6089\n",
      "Epoch 115/5000\n",
      "6376/6376 [==============================] - 1s - loss: 361.5557 - val_loss: 774.3028\n",
      "Epoch 116/5000\n",
      "6376/6376 [==============================] - 1s - loss: 365.1547 - val_loss: 770.2097\n",
      "Epoch 117/5000\n",
      "6376/6376 [==============================] - 1s - loss: 361.2918 - val_loss: 767.3849\n",
      "Epoch 118/5000\n",
      "6376/6376 [==============================] - 1s - loss: 372.1917 - val_loss: 783.3303\n",
      "Epoch 119/5000\n",
      "6376/6376 [==============================] - 1s - loss: 367.7423 - val_loss: 754.8680\n",
      "Fold:  5  of 5\n",
      "Train on 6376 samples, validate on 1594 samples\n",
      "Epoch 1/5000\n",
      "6376/6376 [==============================] - 1s - loss: 7137.3192 - val_loss: 6577.7686\n",
      "Epoch 2/5000\n",
      "6376/6376 [==============================] - 1s - loss: 6221.4969 - val_loss: 6113.0062\n",
      "Epoch 3/5000\n",
      "6376/6376 [==============================] - 1s - loss: 5851.3879 - val_loss: 5891.3194\n",
      "Epoch 4/5000\n",
      "6376/6376 [==============================] - 1s - loss: 5615.2258 - val_loss: 5685.7989\n",
      "Epoch 5/5000\n",
      "6376/6376 [==============================] - 1s - loss: 5398.4959 - val_loss: 5451.3855\n",
      "Epoch 6/5000\n",
      "6376/6376 [==============================] - 1s - loss: 5221.5154 - val_loss: 5248.1910\n",
      "Epoch 7/5000\n",
      "6376/6376 [==============================] - 1s - loss: 4996.6241 - val_loss: 4893.7175\n",
      "Epoch 8/5000\n",
      "6376/6376 [==============================] - 1s - loss: 4826.0543 - val_loss: 4750.7129\n",
      "Epoch 9/5000\n",
      "6376/6376 [==============================] - 1s - loss: 4653.4596 - val_loss: 4659.6059\n",
      "Epoch 10/5000\n",
      "6376/6376 [==============================] - 1s - loss: 4406.1291 - val_loss: 4116.2886\n",
      "Epoch 11/5000\n",
      "6376/6376 [==============================] - 1s - loss: 3773.2068 - val_loss: 3618.9793\n",
      "Epoch 12/5000\n",
      "6376/6376 [==============================] - 1s - loss: 3431.7095 - val_loss: 3335.1290\n",
      "Epoch 13/5000\n",
      "6376/6376 [==============================] - 1s - loss: 3173.2693 - val_loss: 3114.8611\n",
      "Epoch 14/5000\n",
      "6376/6376 [==============================] - 1s - loss: 3030.2864 - val_loss: 3264.0771\n",
      "Epoch 15/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6376/6376 [==============================] - 1s - loss: 2907.4038 - val_loss: 2922.9466\n",
      "Epoch 16/5000\n",
      "6376/6376 [==============================] - 1s - loss: 2740.6364 - val_loss: 2775.7199\n",
      "Epoch 17/5000\n",
      "6376/6376 [==============================] - 1s - loss: 2662.7711 - val_loss: 2642.8118\n",
      "Epoch 18/5000\n",
      "6376/6376 [==============================] - 1s - loss: 2523.2306 - val_loss: 2513.5701\n",
      "Epoch 19/5000\n",
      "6376/6376 [==============================] - 1s - loss: 2420.1421 - val_loss: 2495.0623\n",
      "Epoch 20/5000\n",
      "6376/6376 [==============================] - 1s - loss: 2278.7905 - val_loss: 2423.6593\n",
      "Epoch 21/5000\n",
      "6376/6376 [==============================] - 1s - loss: 2207.5128 - val_loss: 2270.4138\n",
      "Epoch 22/5000\n",
      "6376/6376 [==============================] - 1s - loss: 2115.8080 - val_loss: 2170.2959\n",
      "Epoch 23/5000\n",
      "6376/6376 [==============================] - 1s - loss: 2037.0503 - val_loss: 2058.6193\n",
      "Epoch 24/5000\n",
      "6376/6376 [==============================] - 1s - loss: 1981.8163 - val_loss: 1950.6291\n",
      "Epoch 25/5000\n",
      "6376/6376 [==============================] - 1s - loss: 1887.3002 - val_loss: 1895.0227\n",
      "Epoch 26/5000\n",
      "6376/6376 [==============================] - 1s - loss: 1805.6290 - val_loss: 2188.7696\n",
      "Epoch 27/5000\n",
      "6376/6376 [==============================] - 1s - loss: 1791.2134 - val_loss: 2159.0378\n",
      "Epoch 28/5000\n",
      "6376/6376 [==============================] - 1s - loss: 1718.9358 - val_loss: 1791.1928\n",
      "Epoch 29/5000\n",
      "6376/6376 [==============================] - 1s - loss: 1683.4769 - val_loss: 1725.5760\n",
      "Epoch 30/5000\n",
      "6376/6376 [==============================] - 1s - loss: 1661.4511 - val_loss: 1740.6581\n",
      "Epoch 31/5000\n",
      "6376/6376 [==============================] - 1s - loss: 1597.7174 - val_loss: 1563.3644\n",
      "Epoch 32/5000\n",
      "6376/6376 [==============================] - 1s - loss: 1552.2444 - val_loss: 1880.0397\n",
      "Epoch 33/5000\n",
      "6376/6376 [==============================] - 1s - loss: 1494.7745 - val_loss: 1711.2022\n",
      "Epoch 34/5000\n",
      "6376/6376 [==============================] - 1s - loss: 1484.4069 - val_loss: 1624.8338\n",
      "Epoch 35/5000\n",
      "6376/6376 [==============================] - 1s - loss: 1409.2675 - val_loss: 1597.5425\n",
      "Epoch 36/5000\n",
      "6376/6376 [==============================] - 1s - loss: 1395.0920 - val_loss: 1466.3643\n",
      "Epoch 37/5000\n",
      "6376/6376 [==============================] - 1s - loss: 1346.9621 - val_loss: 1485.2049\n",
      "Epoch 38/5000\n",
      "6376/6376 [==============================] - 1s - loss: 1306.1013 - val_loss: 1674.2763\n",
      "Epoch 39/5000\n",
      "6376/6376 [==============================] - 1s - loss: 1285.3022 - val_loss: 1427.1080\n",
      "Epoch 40/5000\n",
      "6376/6376 [==============================] - 1s - loss: 1273.6333 - val_loss: 1391.7463\n",
      "Epoch 41/5000\n",
      "6376/6376 [==============================] - 1s - loss: 1244.6655 - val_loss: 1324.0857\n",
      "Epoch 42/5000\n",
      "6376/6376 [==============================] - 1s - loss: 1197.3832 - val_loss: 1377.1684\n",
      "Epoch 43/5000\n",
      "6376/6376 [==============================] - 1s - loss: 1234.1434 - val_loss: 1316.2862\n",
      "Epoch 44/5000\n",
      "6376/6376 [==============================] - 1s - loss: 1183.7492 - val_loss: 1312.3270\n",
      "Epoch 45/5000\n",
      "6376/6376 [==============================] - 1s - loss: 1128.5932 - val_loss: 1315.5492\n",
      "Epoch 46/5000\n",
      "6376/6376 [==============================] - 1s - loss: 1136.3750 - val_loss: 1235.4957\n",
      "Epoch 47/5000\n",
      "6376/6376 [==============================] - 1s - loss: 1084.1781 - val_loss: 1554.7099\n",
      "Epoch 48/5000\n",
      "6376/6376 [==============================] - 1s - loss: 1082.5760 - val_loss: 1458.6742\n",
      "Epoch 49/5000\n",
      "6376/6376 [==============================] - 1s - loss: 1057.0264 - val_loss: 1225.8871\n",
      "Epoch 50/5000\n",
      "6376/6376 [==============================] - 1s - loss: 1034.8613 - val_loss: 1145.4674\n",
      "Epoch 51/5000\n",
      "6376/6376 [==============================] - 1s - loss: 1050.8555 - val_loss: 1149.7150\n",
      "Epoch 52/5000\n",
      "6376/6376 [==============================] - 1s - loss: 1035.4106 - val_loss: 1151.6918\n",
      "Epoch 53/5000\n",
      "6376/6376 [==============================] - 1s - loss: 989.9174 - val_loss: 1150.9410\n",
      "Epoch 54/5000\n",
      "6376/6376 [==============================] - 1s - loss: 949.0310 - val_loss: 1198.9079\n",
      "Epoch 55/5000\n",
      "6376/6376 [==============================] - 1s - loss: 949.3032 - val_loss: 1552.2608\n",
      "Epoch 56/5000\n",
      "6376/6376 [==============================] - 1s - loss: 929.1925 - val_loss: 1149.8841\n",
      "Epoch 57/5000\n",
      "6376/6376 [==============================] - 1s - loss: 921.9710 - val_loss: 1155.2708\n",
      "Epoch 58/5000\n",
      "6376/6376 [==============================] - 1s - loss: 907.9383 - val_loss: 1124.2414\n",
      "Epoch 59/5000\n",
      "6376/6376 [==============================] - 1s - loss: 898.3301 - val_loss: 1335.2801\n",
      "Epoch 60/5000\n",
      "6376/6376 [==============================] - 1s - loss: 874.6218 - val_loss: 1025.7254\n",
      "Epoch 61/5000\n",
      "6376/6376 [==============================] - 1s - loss: 860.2043 - val_loss: 1087.9894\n",
      "Epoch 62/5000\n",
      "6376/6376 [==============================] - 1s - loss: 844.4229 - val_loss: 1079.6483\n",
      "Epoch 63/5000\n",
      "6376/6376 [==============================] - 1s - loss: 853.7685 - val_loss: 1030.2718\n",
      "Epoch 64/5000\n",
      "6376/6376 [==============================] - 1s - loss: 822.4643 - val_loss: 966.0214\n",
      "Epoch 65/5000\n",
      "6376/6376 [==============================] - 1s - loss: 800.4538 - val_loss: 1036.7732\n",
      "Epoch 66/5000\n",
      "6376/6376 [==============================] - 1s - loss: 798.9688 - val_loss: 1115.8373\n",
      "Epoch 67/5000\n",
      "6376/6376 [==============================] - 1s - loss: 777.1608 - val_loss: 982.5430\n",
      "Epoch 68/5000\n",
      "6376/6376 [==============================] - 1s - loss: 765.2160 - val_loss: 987.1503\n",
      "Epoch 69/5000\n",
      "6376/6376 [==============================] - 1s - loss: 773.7108 - val_loss: 946.3621\n",
      "Epoch 70/5000\n",
      "6376/6376 [==============================] - 1s - loss: 746.5989 - val_loss: 880.7897\n",
      "Epoch 71/5000\n",
      "6376/6376 [==============================] - 1s - loss: 742.3705 - val_loss: 901.3161\n",
      "Epoch 72/5000\n",
      "6376/6376 [==============================] - 1s - loss: 742.5293 - val_loss: 896.6544\n",
      "Epoch 73/5000\n",
      "6376/6376 [==============================] - 1s - loss: 725.3554 - val_loss: 925.1026\n",
      "Epoch 74/5000\n",
      "6376/6376 [==============================] - 1s - loss: 711.9493 - val_loss: 874.6530\n",
      "Epoch 75/5000\n",
      "6376/6376 [==============================] - 1s - loss: 677.8572 - val_loss: 981.2396\n",
      "Epoch 76/5000\n",
      "6376/6376 [==============================] - 1s - loss: 708.2548 - val_loss: 1048.5125\n",
      "Epoch 77/5000\n",
      "6376/6376 [==============================] - 1s - loss: 665.6581 - val_loss: 825.3376\n",
      "Epoch 78/5000\n",
      "6376/6376 [==============================] - 1s - loss: 676.8900 - val_loss: 842.4443\n",
      "Epoch 79/5000\n",
      "6376/6376 [==============================] - 1s - loss: 660.3678 - val_loss: 845.9968\n",
      "Epoch 80/5000\n",
      "6376/6376 [==============================] - 1s - loss: 642.5627 - val_loss: 891.4466\n",
      "Epoch 81/5000\n",
      "6376/6376 [==============================] - 1s - loss: 654.0507 - val_loss: 812.6199\n",
      "Epoch 82/5000\n",
      "6376/6376 [==============================] - 1s - loss: 626.6523 - val_loss: 966.4262\n",
      "Epoch 83/5000\n",
      "6376/6376 [==============================] - 1s - loss: 621.8901 - val_loss: 853.7446\n",
      "Epoch 84/5000\n",
      "6376/6376 [==============================] - 1s - loss: 611.1501 - val_loss: 915.7217\n",
      "Epoch 85/5000\n",
      "6376/6376 [==============================] - 1s - loss: 577.1374 - val_loss: 886.8007\n",
      "Epoch 86/5000\n",
      "6376/6376 [==============================] - 1s - loss: 602.7625 - val_loss: 834.6728\n",
      "Epoch 87/5000\n",
      "6376/6376 [==============================] - 1s - loss: 595.8036 - val_loss: 796.4316\n",
      "Epoch 88/5000\n",
      "6376/6376 [==============================] - 1s - loss: 586.6160 - val_loss: 809.0710\n",
      "Epoch 89/5000\n",
      "6376/6376 [==============================] - 1s - loss: 557.2482 - val_loss: 1047.2507\n",
      "Epoch 90/5000\n",
      "6376/6376 [==============================] - 1s - loss: 567.5908 - val_loss: 791.9634\n",
      "Epoch 91/5000\n",
      "6376/6376 [==============================] - 1s - loss: 547.6468 - val_loss: 723.2488\n",
      "Epoch 92/5000\n",
      "6376/6376 [==============================] - 1s - loss: 557.8740 - val_loss: 756.9886\n",
      "Epoch 93/5000\n",
      "6376/6376 [==============================] - 1s - loss: 529.7472 - val_loss: 792.6162\n",
      "Epoch 94/5000\n",
      "6376/6376 [==============================] - 1s - loss: 539.2491 - val_loss: 758.2511\n",
      "Epoch 95/5000\n",
      "6376/6376 [==============================] - 1s - loss: 520.9916 - val_loss: 795.4063\n",
      "Epoch 96/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6376/6376 [==============================] - 1s - loss: 520.5087 - val_loss: 787.0001\n",
      "Epoch 97/5000\n",
      "6376/6376 [==============================] - 1s - loss: 519.3456 - val_loss: 900.2827\n",
      "Epoch 98/5000\n",
      "6376/6376 [==============================] - 1s - loss: 489.6738 - val_loss: 711.3718\n",
      "Epoch 99/5000\n",
      "6376/6376 [==============================] - 1s - loss: 517.0751 - val_loss: 910.6758\n",
      "Epoch 100/5000\n",
      "6376/6376 [==============================] - 1s - loss: 471.5710 - val_loss: 723.7327\n",
      "Epoch 101/5000\n",
      "6376/6376 [==============================] - 1s - loss: 491.7549 - val_loss: 669.1869\n",
      "Epoch 102/5000\n",
      "6376/6376 [==============================] - 1s - loss: 484.9131 - val_loss: 713.8167\n",
      "Epoch 103/5000\n",
      "6376/6376 [==============================] - 1s - loss: 473.2657 - val_loss: 813.9211\n",
      "Epoch 104/5000\n",
      "6376/6376 [==============================] - 1s - loss: 480.5117 - val_loss: 679.2830\n",
      "Epoch 105/5000\n",
      "6376/6376 [==============================] - 1s - loss: 434.2766 - val_loss: 652.2833\n",
      "Epoch 106/5000\n",
      "6376/6376 [==============================] - 1s - loss: 452.7777 - val_loss: 704.8214\n",
      "Epoch 107/5000\n",
      "6376/6376 [==============================] - 1s - loss: 456.6274 - val_loss: 736.6357\n",
      "Epoch 108/5000\n",
      "6376/6376 [==============================] - 1s - loss: 433.7245 - val_loss: 652.3531\n",
      "Epoch 109/5000\n",
      "6376/6376 [==============================] - 1s - loss: 428.8125 - val_loss: 824.1831\n",
      "Epoch 110/5000\n",
      "6376/6376 [==============================] - 1s - loss: 444.5077 - val_loss: 652.1840\n",
      "Epoch 111/5000\n",
      "6376/6376 [==============================] - 1s - loss: 430.1300 - val_loss: 648.2080\n",
      "Epoch 112/5000\n",
      "6376/6376 [==============================] - 1s - loss: 410.6797 - val_loss: 705.3412\n",
      "Epoch 113/5000\n",
      "6376/6376 [==============================] - 1s - loss: 423.8999 - val_loss: 664.7235\n",
      "Epoch 114/5000\n",
      "6376/6376 [==============================] - 1s - loss: 409.4592 - val_loss: 675.3809\n",
      "Epoch 115/5000\n",
      "6376/6376 [==============================] - 1s - loss: 405.4892 - val_loss: 673.4564\n",
      "Epoch 116/5000\n",
      "6376/6376 [==============================] - 1s - loss: 392.6253 - val_loss: 661.8525\n",
      "Epoch 117/5000\n",
      "6376/6376 [==============================] - 1s - loss: 404.2401 - val_loss: 661.9643\n",
      "Epoch 118/5000\n",
      "6376/6376 [==============================] - 1s - loss: 398.2023 - val_loss: 666.7580\n",
      "Epoch 119/5000\n",
      "6376/6376 [==============================] - 1s - loss: 397.0360 - val_loss: 642.3060\n",
      "Epoch 120/5000\n",
      "6376/6376 [==============================] - 1s - loss: 381.5794 - val_loss: 605.1201\n",
      "Epoch 121/5000\n",
      "6376/6376 [==============================] - 1s - loss: 372.7137 - val_loss: 637.5249\n",
      "Epoch 122/5000\n",
      "6376/6376 [==============================] - 1s - loss: 371.2812 - val_loss: 616.2542\n",
      "Epoch 123/5000\n",
      "6376/6376 [==============================] - 1s - loss: 360.8227 - val_loss: 593.8079\n",
      "Epoch 124/5000\n",
      "6376/6376 [==============================] - 1s - loss: 375.0866 - val_loss: 585.5811\n",
      "Epoch 125/5000\n",
      "6376/6376 [==============================] - 1s - loss: 363.7302 - val_loss: 639.2583\n",
      "Epoch 126/5000\n",
      "6376/6376 [==============================] - 1s - loss: 349.9709 - val_loss: 606.5776\n",
      "Epoch 127/5000\n",
      "6376/6376 [==============================] - 1s - loss: 354.8518 - val_loss: 596.8246\n",
      "Epoch 128/5000\n",
      "6376/6376 [==============================] - 1s - loss: 346.6878 - val_loss: 715.7590\n",
      "Epoch 129/5000\n",
      "6376/6376 [==============================] - 1s - loss: 329.9957 - val_loss: 615.8336\n",
      "Epoch 130/5000\n",
      "6376/6376 [==============================] - 1s - loss: 347.8486 - val_loss: 626.1602\n",
      "Epoch 131/5000\n",
      "6376/6376 [==============================] - 1s - loss: 333.7910 - val_loss: 603.9568\n",
      "Epoch 132/5000\n",
      "6376/6376 [==============================] - 1s - loss: 317.2335 - val_loss: 567.6454\n",
      "Epoch 133/5000\n",
      "6376/6376 [==============================] - 1s - loss: 327.7981 - val_loss: 546.7731\n",
      "Epoch 134/5000\n",
      "6376/6376 [==============================] - 1s - loss: 317.4219 - val_loss: 564.1696\n",
      "Epoch 135/5000\n",
      "6376/6376 [==============================] - 1s - loss: 321.7234 - val_loss: 556.2905\n",
      "Epoch 136/5000\n",
      "6376/6376 [==============================] - 1s - loss: 334.8000 - val_loss: 563.5226\n",
      "Epoch 137/5000\n",
      "6376/6376 [==============================] - 1s - loss: 313.5280 - val_loss: 566.3712\n",
      "Epoch 138/5000\n",
      "6376/6376 [==============================] - 1s - loss: 316.3391 - val_loss: 571.9873\n",
      "Epoch 139/5000\n",
      "6376/6376 [==============================] - 1s - loss: 307.5294 - val_loss: 557.1475\n",
      "Epoch 140/5000\n",
      "6376/6376 [==============================] - 1s - loss: 296.2439 - val_loss: 574.9333\n",
      "Epoch 141/5000\n",
      "6376/6376 [==============================] - 1s - loss: 298.9637 - val_loss: 542.3244\n",
      "Epoch 142/5000\n",
      "6376/6376 [==============================] - 1s - loss: 291.5424 - val_loss: 540.3227\n",
      "Epoch 143/5000\n",
      "6376/6376 [==============================] - 1s - loss: 291.1528 - val_loss: 569.9699\n",
      "Epoch 144/5000\n",
      "6376/6376 [==============================] - 1s - loss: 286.3688 - val_loss: 554.9993\n",
      "Epoch 145/5000\n",
      "6376/6376 [==============================] - 1s - loss: 287.7261 - val_loss: 569.5399\n",
      "Epoch 146/5000\n",
      "6376/6376 [==============================] - 1s - loss: 280.8937 - val_loss: 548.5715\n",
      "Epoch 147/5000\n",
      "6376/6376 [==============================] - 1s - loss: 281.4415 - val_loss: 618.9089\n",
      "Epoch 148/5000\n",
      "6376/6376 [==============================] - 1s - loss: 268.5577 - val_loss: 608.4946\n",
      "Epoch 149/5000\n",
      "6376/6376 [==============================] - 1s - loss: 273.6268 - val_loss: 541.2273\n",
      "Epoch 150/5000\n",
      "6376/6376 [==============================] - 1s - loss: 265.1308 - val_loss: 544.0742\n",
      "Epoch 151/5000\n",
      "6376/6376 [==============================] - 1s - loss: 275.0224 - val_loss: 528.1448\n",
      "Epoch 152/5000\n",
      "6376/6376 [==============================] - 1s - loss: 266.3950 - val_loss: 551.5629\n",
      "Epoch 153/5000\n",
      "6376/6376 [==============================] - 1s - loss: 260.9182 - val_loss: 506.9271\n",
      "Epoch 154/5000\n",
      "6376/6376 [==============================] - 1s - loss: 259.4961 - val_loss: 509.7389\n",
      "Epoch 155/5000\n",
      "6376/6376 [==============================] - 1s - loss: 253.9584 - val_loss: 519.2458\n",
      "Epoch 156/5000\n",
      "6376/6376 [==============================] - 1s - loss: 252.0152 - val_loss: 575.5272\n",
      "Epoch 157/5000\n",
      "6376/6376 [==============================] - 1s - loss: 256.4649 - val_loss: 523.3826\n",
      "Epoch 158/5000\n",
      "6376/6376 [==============================] - 1s - loss: 240.2748 - val_loss: 500.8678\n",
      "Epoch 159/5000\n",
      "6376/6376 [==============================] - 1s - loss: 245.2540 - val_loss: 507.6261\n",
      "Epoch 160/5000\n",
      "6376/6376 [==============================] - 1s - loss: 238.8857 - val_loss: 507.1602\n",
      "Epoch 161/5000\n",
      "6376/6376 [==============================] - 1s - loss: 230.5633 - val_loss: 527.9743\n",
      "Epoch 162/5000\n",
      "6376/6376 [==============================] - 1s - loss: 237.7944 - val_loss: 523.7771\n",
      "Epoch 163/5000\n",
      "6376/6376 [==============================] - 1s - loss: 243.2377 - val_loss: 503.6362\n",
      "Epoch 164/5000\n",
      "6376/6376 [==============================] - 1s - loss: 228.3179 - val_loss: 528.0983\n",
      "Epoch 165/5000\n",
      "6376/6376 [==============================] - 1s - loss: 231.7070 - val_loss: 504.1464\n",
      "Epoch 166/5000\n",
      "6376/6376 [==============================] - 1s - loss: 226.3408 - val_loss: 493.0291\n",
      "Epoch 167/5000\n",
      "6376/6376 [==============================] - 1s - loss: 236.5053 - val_loss: 487.3562\n",
      "Epoch 168/5000\n",
      "6376/6376 [==============================] - 1s - loss: 223.0642 - val_loss: 517.8281\n",
      "Epoch 169/5000\n",
      "6376/6376 [==============================] - 1s - loss: 221.4303 - val_loss: 487.5997\n",
      "Epoch 170/5000\n",
      "6376/6376 [==============================] - 1s - loss: 216.2262 - val_loss: 495.5004\n",
      "Epoch 171/5000\n",
      "6376/6376 [==============================] - 1s - loss: 219.6624 - val_loss: 503.5094\n",
      "Epoch 172/5000\n",
      "6376/6376 [==============================] - 1s - loss: 215.1496 - val_loss: 522.5224\n",
      "Epoch 173/5000\n",
      "6376/6376 [==============================] - 1s - loss: 222.8235 - val_loss: 479.2092\n",
      "Epoch 174/5000\n",
      "6376/6376 [==============================] - 1s - loss: 212.4268 - val_loss: 484.9789\n",
      "Epoch 175/5000\n",
      "6376/6376 [==============================] - 1s - loss: 205.2198 - val_loss: 492.7296\n",
      "Epoch 176/5000\n",
      "6376/6376 [==============================] - 1s - loss: 210.3876 - val_loss: 488.0995\n",
      "Epoch 177/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6376/6376 [==============================] - 1s - loss: 210.3317 - val_loss: 493.7397\n",
      "Epoch 178/5000\n",
      "6376/6376 [==============================] - 1s - loss: 205.4376 - val_loss: 498.0517\n",
      "Epoch 179/5000\n",
      "6376/6376 [==============================] - 1s - loss: 202.4241 - val_loss: 506.2159\n",
      "Epoch 180/5000\n",
      "6376/6376 [==============================] - 1s - loss: 203.6424 - val_loss: 494.5065\n",
      "Epoch 181/5000\n",
      "6376/6376 [==============================] - 1s - loss: 196.7783 - val_loss: 490.3729\n",
      "Epoch 182/5000\n",
      "6376/6376 [==============================] - 1s - loss: 195.7878 - val_loss: 482.5718\n",
      "Epoch 183/5000\n",
      "6376/6376 [==============================] - 1s - loss: 194.5505 - val_loss: 481.6022\n",
      "Epoch 184/5000\n",
      "6376/6376 [==============================] - 1s - loss: 188.4739 - val_loss: 488.7773\n",
      "Obtained loss:  482.325736898  ( 150.580793656 )\n"
     ]
    }
   ],
   "source": [
    "############## PREPARING DATA ##################################################\n",
    "\n",
    "dataset_trans = pd.read_table(os.path.join('data','dataset_trans.csv'),sep=',')\n",
    "target = np.asarray(dataset_trans['Y'])\n",
    "pazienti = np.asarray(dataset_trans['subj'])\n",
    "del dataset_trans['Y']\n",
    "del dataset_trans['min_risk']\n",
    "\n",
    "train = np.asarray(dataset_trans)\n",
    "train_val_size = 0.8 #80% training+validation set and 20% test set\n",
    "train_size = 0.7 #70% training set and 30% validation set\n",
    "X_tr_val, X_te, Y_tr_val, Y_te = train_test_split(train, target, train_size=train_val_size, random_state=1)\n",
    "X_tr, X_val, Y_tr, Y_val = train_test_split(X_tr_val, Y_tr_val, train_size=train_size, random_state=1)\n",
    "\n",
    "paz_tr_val = X_tr_val[:,0]\n",
    "paz_tr = X_tr[:,0]\n",
    "paz_val = X_val[:,0]\n",
    "paz_te = X_te[:,0]\n",
    "X_tr_val = X_tr_val[:,1:14]\n",
    "X_tr = X_tr[:,1:14]\n",
    "X_val = X_val[:,1:14]\n",
    "X_te = X_te[:,1:14]\n",
    "\n",
    "scaler = StandardScaler().fit(X_tr)\n",
    "X_tr = scaler.transform(X_tr)\n",
    "X_val = scaler.transform(X_val)\n",
    "X_te = scaler.transform(X_te)\n",
    "\n",
    "model, score = train_nn(X_tr,Y_tr,X_val,Y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Score NN:  324.65161397\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYMAAAD8CAYAAACVZ8iyAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nkBYI80ktrwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2605cb34080>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD8CAYAAAB5Pm/hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nGfSS1DmDXpI69/8ARAbvXdIsOIgAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x26065b49390>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYMAAAD8CAYAAACVZ8iyAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x26065484dd8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "############## EVALUATING RESULTS  #############################################\n",
    "Y_te = np.squeeze(Y_te)\n",
    "Y_NN = np.squeeze(model.predict(X_te))\n",
    "\n",
    "#MSE\n",
    "print('\\n Score NN: ',mean_squared_error(Y_NN,Y_te))\n",
    "\n",
    "#Plot train and validation losses\n",
    "#plt.plot(loss.losses)\n",
    "#plt.plot(loss.val_losses)\n",
    "#plt.show()\n",
    "\n",
    "#Boxplot of the difference between actual values and estimates\n",
    "data_to_plot = [Y_te-Y_NN]\n",
    "plt.boxplot(data_to_plot)\n",
    "plt.show()\n",
    "\n",
    "#Histogram of the difference between actual values and estimates\n",
    "plt.hist(data_to_plot,bins=40)\n",
    "plt.show()\n",
    "\n",
    "#Plot of the actual values and estimates\n",
    "plt.plot(Y_te, marker='^')\n",
    "plt.plot(Y_NN, marker='o')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.save('Y_NN',Y_NN)\n",
    "np.save('Y_te',Y_te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
